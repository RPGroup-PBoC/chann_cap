{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy Approximation - Joint distribution P(m, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2018 Manuel Razo. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import dill\n",
    "import itertools\n",
    "\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import library to perform maximum entropy fits\n",
    "from maxentropy.skmaxent import FeatureTransformer, MinDivergenceModel\n",
    "# Import libraries to parallelize processes\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Import matplotlib stuff for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Seaborn, useful for graphics\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the utils for this project\n",
    "import chann_cap_utils as chann_cap\n",
    "\n",
    "# Set PBoC plotting style\n",
    "chann_cap.set_plotting_style()\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline (only use with static plots (non-Bokeh))\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "tmpdir = '../../tmp/'\n",
    "figdir = '../../fig/MaxEnt_approx_joint/'\n",
    "datadir = '../../data/csv_maxEnt_dist/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\LaTeX$ macros\n",
    "\n",
    "$\\newcommand{kpon}{k^p_{\\text{on}}}$\n",
    "$\\newcommand{kpoff}{k^p_{\\text{off}}}$\n",
    "$\\newcommand{kron}{k^r_{\\text{on}}}$\n",
    "$\\newcommand{kroff}{k^r_{\\text{off}}}$\n",
    "$\\newcommand{rm}{r _m}$\n",
    "$\\newcommand{rp}{r _p}$\n",
    "$\\newcommand{gm}{\\gamma _m}$\n",
    "$\\newcommand{gp}{\\gamma _p}$\n",
    "$\\newcommand{mm}{\\left\\langle m \\right\\rangle}$\n",
    "$\\newcommand{foldchange}{\\text{fold-change}}$\n",
    "$\\newcommand{avg}[1]{\\left\\langle #1 \\right\\rangle}$\n",
    "$\\newcommand{ee}[1]{\\left\\langle #1 \\right\\rangle}$\n",
    "$\\newcommand{bb}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{ll}[1]{\\underset{\\sim}{#1}}$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The joint distribution $P(m, p)$ using MaxEnt.\n",
    "\n",
    "So far we used the MaxEnt approach to approximate the marginal distributions for mRNA $P(m)$ and protein $P(p)$. In reality since the protein copy number depends on the mRNA count we have a joint distribution $P(m, p)$. By definition the marginals we have computed are of the form\n",
    "$$\n",
    "P(m) \\equiv \\sum_p P(m, p),\n",
    "\\tag{1}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "P(p) \\equiv \\sum_m P(m, p),\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "This joint distribution could contain relevant information that we lose when performing these marginalizations. Therefore in this notebook we will use the exact same MaxEnt approach as before to compute the joint distribution.\n",
    "\n",
    "For the case of the joing distribution we have moments for the mRNA marginal distribution\n",
    "$$\n",
    "\\ee{m^i} \\equiv \\sum_m \\sum_p m^i P(m, p),\n",
    "\\tag{3}\n",
    "$$\n",
    "and equivalent moments for the protein distribution\n",
    "$$\n",
    "\\ee{p^i} \\equiv \\sum_m \\sum_p p^i P(m, p).\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "We also know the steady-state value of cross-correlations of the form\n",
    "$$\n",
    "\\ee{m^i p^j} \\equiv \\sum_m \\sum_p m^i p^j P(m, p), \n",
    "\\tag{5}\n",
    "$$\n",
    "where $i, j \\in \\{1, 2\\}$.\n",
    "\n",
    "Using these moments we can follow the exact same strategy to compute the MaxEnt approximation of the joint distribution.\n",
    "\n",
    "That means that our MaxEnt approximate joint distribution $P_H(m, p)$ is of the form\n",
    "$$\n",
    "P_H(m, p) = {1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "\\sum_{i=1}^3\\lambda_i^{(m)} m^i +\n",
    "\\sum_{j=1}^3\\lambda_j^{(p)} p^j +\n",
    "\\sum_{i,j \\in \\{1, 2\\}}\\lambda_{ij}^{(mp)} m^i p^j\n",
    "\\right],\n",
    "\\tag{6}\n",
    "$$\n",
    "where all the $\\lambda$ terms represent the Lagrange multipliers that need to be numerically determined.\n",
    "\n",
    "Given this form of the distribution the MaxEnt moments $\\ee{m^ip^j}_H$ are given by\n",
    "$$\n",
    "\\ee{m^ip^j}_H \\equiv \\sum_m \\sum_p m^ip^j P_H(m, p).\n",
    "\\tag{7}\n",
    "$$\n",
    "\n",
    "Let's now look into how to obtain the value of the Lagrange multipliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Newton-Raphson algorithm\n",
    "\n",
    "Following [Smadbeck & Kaznessis, 2013](http://www.pnas.org/content/110/35/14261) we will use a Newton-Raphson algorithm to get at the value of these Lagrange multipliers.\n",
    "\n",
    "Let $\\ll{\\lambda}$ be an array containing all Lagrange multipliers, and $\\ll{\\mu_H}$ be the estimate of all the MaxEnt moments computed using $P_H(m, p)$. The steps listed by the authors go as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize Lagrange multipliers $\\ll{\\lambda} = \\ll{\\lambda_0}$ (Typically a guess of all zeros works).\n",
    "2. Calculate the joint distribution $P_H(m, p)$ as determined by Eq. 6.\n",
    "3. Calculate the moments used for the constraints $\\ll{\\mu_H}$ with Eq. 7.\n",
    "4. Calculate the difference between the **known** moments and the MaxEnt estimates as\n",
    "$$\n",
    "\\Delta\\ll{\\mu} = \\ll{\\mu} - \\ll{\\mu_H}.\n",
    "\\tag{8}\n",
    "$$\n",
    "5. Calculate the 2-norm error with\n",
    "$$\n",
    "\\varepsilon = \\ll{\\mu_H}^T \\ll{\\mu_H}\n",
    "\\tag{9}\n",
    "$$\n",
    "6. If $\\varepsilon \\leq$ `tol` (i.e. a user determined tolerance value) proceed to the last step 7. Otherwise\n",
    "\n",
    "    a. Calculate the Jacobian Matrix $\\bb{J}$ with entries\n",
    "    $$\n",
    "    J_{i,j} \\equiv {\\partial \\mu_{H,i} \\over \\partial \\lambda_j}.\n",
    "    \\tag{10}\n",
    "    $$\n",
    "    (We'll come back to how to compute this matrix)\n",
    "    b. The Newton-Raphson method uses a first-order Taylor expansion of the form\n",
    "    $$\n",
    "    \\Delta\\ll{\\mu} \\approx \\bb{J} \\Delta \\ll{\\lambda}.\n",
    "    \\tag{11}\n",
    "    $$\n",
    "    Therefore we can estimate the step size for each of our Lagrange multipliers\n",
    "    as\n",
    "    $$\n",
    "    \\Delta \\ll{\\lambda} \\approx \\bb{J}^{-1} \\Delta\\ll{\\mu}\n",
    "    \\tag{12}\n",
    "    $$\n",
    "    c. Using this approximation we update our estimates for the i$^{\\text{th}}$\n",
    "    iteration as\n",
    "    $$\n",
    "    \\ll{\\lambda}^{(i + 1)} = \\ll{\\lambda}^{(i)} + \\Delta \\ll{\\lambda}\n",
    "    \\tag{13}\n",
    "    $$\n",
    "    d. Repeat from step 2.\n",
    "7. Once the $\\varepsilon \\leq$ `tol` relationship is satisfied return the Lagrange multipliers values $\\ll{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian Matrix $\\bb{J}$\n",
    "\n",
    "To compute the derivative from Eq. 10 we need to be very careful with the indexing. First we will rewrite the MaxEnt distribution (Eq. 6) as\n",
    "$$\n",
    "P_H(m, p) = {1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "- \\sum_{i=1}^N \\lambda_i m^{x_i} p^{y_i},\n",
    "\\right],\n",
    "\\tag{14}\n",
    "$$\n",
    "where we index all Lagrange multipliers $\\lambda_i$ to be associated with each of the constraints of the form $\\ee{m^{x_i} p^{y_i}}$. In our specific case we have the Lagrange multipliers of the form:\n",
    "$$\n",
    "\\left\\{\n",
    "\\lambda_1 : \\ee{m},\n",
    "\\lambda_2 : \\ee{m^2},\n",
    "\\lambda_3 : \\ee{m^3},\\\\\n",
    "\\lambda_4 : \\ee{p},\n",
    "\\lambda_5 : \\ee{p^2},\n",
    "\\lambda_6 : \\ee{p^3},\\\\\n",
    "\\lambda_7 : \\ee{mp},\n",
    "\\lambda_8 : \\ee{m^2p},\n",
    "\\lambda_9 : \\ee{mp^2},\n",
    "\\right\\}\n",
    "\\tag{15}\n",
    "$$\n",
    "\n",
    "This implies that Eq. 10 is given by\n",
    "$$\n",
    "J_{i,j} = {\\partial \\over \\partial \\lambda_j} \\ee{m^{x_i} p^{y_j}}_H.\n",
    "\\tag{16}\n",
    "$$\n",
    "Combining Eq. 7 and Eq. 14 gives\n",
    "$$\n",
    "J_{i,j} = {\\partial \\over \\partial \\lambda_j}\\left(\n",
    "\\sum_m \\sum_p m^{x_i} p^{y_i}\n",
    "{1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "- \\sum_{k=1}^N \\lambda_k m^{x_k} p^{y_k},\n",
    "\\right]\n",
    "\\right).\n",
    "\\tag{17}\n",
    "$$\n",
    "Evaluating this derivative gives\n",
    "$$\n",
    "J_{i,j} = \\sum_m \\sum_p \\left( m^{x_i} p^{y_i} \\right)\n",
    "\\left( - m^{x_j} p^{y_j}  \\right)\n",
    "{1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "- \\sum_{k=1}^N \\lambda_k m^{x_k} p^{y_k}\n",
    "\\right].\n",
    "\\tag{18}\n",
    "$$\n",
    "This is simplified to\n",
    "$$\n",
    "J_{i,j} = - \\ee{m^{x_i + x_j} p ^{y_i + y_j}}_H\n",
    "\\tag{19}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the algorithm.\n",
    "\n",
    "In the following steps we will be implementing such algorithm\n",
    "\n",
    "The first thing we will define is a function to compute the \"product space\" $m^x p^y$ for a given selection of $m$ andp $p$ values. These products will be fed to the algorithm as a pre-computed entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_space(mRNA, protein, exponents=[0, 0]):\n",
    "    '''\n",
    "    Computes all the products of the form m**x * p**y for all possible pairs\n",
    "    of m and p given in the mRNA and protein arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mRNA, protein : array-like.\n",
    "        Selected range of mRNA and protein to be used as sample space for the\n",
    "        distribution\n",
    "    exponents : array-like. 2x1\n",
    "        Exponents for the product.\n",
    "        exponents[0] = mRNA exponent x\n",
    "        exponents[1] = mRNA exponent y\n",
    "    Returns\n",
    "    -------\n",
    "    prod_space : array-like. len(mRNA) x len(protein).\n",
    "        All possible pairwise products.\n",
    "        rows = mRNA\n",
    "        columns = protein\n",
    "    '''\n",
    "    # Build mRNA and protein grid\n",
    "    mm, pp = np.meshgrid(mRNA, protein)\n",
    "    \n",
    "    # Compute product and return all possible pairwise products\n",
    "    return (mm**exponents[0] * pp**exponents[1]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having this in hand let's define a function that takes an array of Lagrange multipliers `lambda_array` and a 3D array `products` of pre-computed products products and returns the **MaxEnt** probability distribution for each entry $(m, p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxEnt_joint_dist(lambda_array, products):\n",
    "    '''\n",
    "    Computs the MaxEnt probability distribution given constraints captured\n",
    "    by the Lagrange multipliers in the lambda_array list and all the products\n",
    "    associated with each of the Lagrange multipliers\n",
    "    Parameters\n",
    "    ----------\n",
    "    lambda_array : array-like. 1 x N.\n",
    "        List of Lagrange multipliers to be used to compute the MaxEnt\n",
    "        distribution.\n",
    "        N = Number of constraints\n",
    "    product : ndarray. mRNA x protein x N\n",
    "        3D array with matrices containing the products associated with each\n",
    "        of the Lagrange multipliers.\n",
    "    Returns\n",
    "    -------\n",
    "    MaxEnt_dist: array-like. len(mRNA) x len(protein)\n",
    "        Maximum entropy distribution for each pairwise m,p entry\n",
    "    '''\n",
    "    # Confirm that the number of constraints is the same as the number of \n",
    "    # associated products\n",
    "    if len(lambda_array) != products.shape[0]:\n",
    "        raise ValueError('The number of constraints must be the same as '+\\\n",
    "                         'the number of given products')\n",
    "    \n",
    "    # Compute the products and exponentiate\n",
    "    exp_lambdas_mp = np.exp(- np.sum(products * \\\n",
    "                           np.array(lambda_array)[:, np.newaxis, np.newaxis],\n",
    "                               axis=0))\n",
    "    # return the distribution\n",
    "    return exp_lambdas_mp / np.sum(exp_lambdas_mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function that computes the moment $\\bb{m^x p^y}_H$ as defined in Eq. 7 **given a pre-computed** maximum entropy distribution P_H(m, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxEnt_joint_moment(mRNA, protein, dist, exponents):\n",
    "    '''\n",
    "    Computes the moment <m**x * p**y> given a pre-computed distribution\n",
    "    dist and sample space mRNA and protein.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mRNA, protein : array-like.\n",
    "        Selected range of mRNA and protein to be used as sample space for the\n",
    "        distribution\n",
    "    dist : array-like. len(mRNA) x len(protein)\n",
    "        Joint distribution of protein and mRNA.\n",
    "    exponents : array-like. 2x1\n",
    "        Exponents for the product.\n",
    "        exponents[0] = mRNA exponent x\n",
    "        exponents[1] = mRNA exponent y\n",
    "    '''\n",
    "    # Check that the distribution is the same size as the sample space\n",
    "    if (len(mRNA) != dist.shape[0]) or (len(protein) != dist.shape[1]):\n",
    "        raise ValueError('The sample space and the distribution have' +\\\n",
    "                        'different sizes.')\n",
    "    \n",
    "    # Perform product and multiply by probability distribution\n",
    "    return np.sum(product_space(mRNA, protein, exponents) * dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the functions that we need to implement the algorithm. Now we will define a function that takes as input an mRNA and protein sample space, a list with the constraints and a list with the associated exponents for each constraint, and finally an optional set of initial guess for the Lagrange multipliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxEnt_newton_raphson(mRNA, protein, constraints, exponents, \n",
    "                          lambda0=None, tol=1E-4, maxiter=1000, \n",
    "                          verbose=False, loop_print=25):\n",
    "    '''\n",
    "    Implementation of the Newton-Raphson algorithm as defined by Smadbeck &\n",
    "    Kaznessis, PNAS, 2013 to find the value of the Lagrange Multipliers that\n",
    "    give the MaxEnt approximation to the joint distribution P(mRNA, protein).\n",
    "    Parameters\n",
    "    ----------\n",
    "    mRNA, protein : array-like.\n",
    "        Selected range of mRNA and protein to be used as sample space for the\n",
    "        distribution\n",
    "    constraints : array-like.\n",
    "        Target constraints for the moments in the distribution. This are the\n",
    "        expected moments of the form <m**x * p**y> that the MaxEnt dist is\n",
    "        trying to satisfy\n",
    "    exponents : list. len(constraints)\n",
    "        A list of the exponents associated with each of the constraints\n",
    "        Each entry in the list is a array-like. 2x1\n",
    "            Exponents for the product.\n",
    "            exponents[0] = mRNA exponent x\n",
    "            exponents[1] = mRNA exponent y\n",
    "    lambda0 : array-like. len(constraints). Default None\n",
    "        Initial guess for the Lagrange multipliers. There should be one\n",
    "        initial guess for each of the constraints. If not given the algorithm\n",
    "        assumes zero as the initial guess for all entries.\n",
    "    tol : float.\n",
    "        Target tolerance for the stop criteria of the algorithm\n",
    "    maxiter : int. Default = 1000\n",
    "        Maximum number of iterations of the algorithm\n",
    "    verbose : bool. Default = False\n",
    "        boolean indicating if the information at each iteration should be\n",
    "        printed\n",
    "    loop_print : int. Default = 25\n",
    "        If verbose is True it prints the loop every loop_print loops\n",
    "    Returns\n",
    "    -------\n",
    "    List of Lagrange multipliers that satisfy the distribution.\n",
    "    '''\n",
    "    # 1. Initialize array of lambdas\n",
    "    # Check if not given lambdas initialize them as zeros\n",
    "    if lambda0 == None:\n",
    "        lambdas = np.zeros(len(constraints))\n",
    "    else:\n",
    "        lambdas = lambda0\n",
    "\n",
    "    # Check that the number of constraints and given exponents is consistent\n",
    "    if (len(constraints) != len(exponents)) or \\\n",
    "    (len(constraints) != len(lambdas)):\n",
    "        raise ValueError('The number of constraints and associated' +\\\n",
    "                            'exponents and inital lambdas must be equal')\n",
    "\n",
    "    # == Pre-compute products associated with the exponents == #\n",
    "    # Initialize matrix to save products\n",
    "    products = np.zeros([len(constraints), len(mRNA), len(protein)])\n",
    "    # Compute each of the products and store them\n",
    "    for i, expo in enumerate(exponents):\n",
    "        products[i, :, :] = product_space(mRNA, protein, expo)\n",
    "    \n",
    "    # Initialize loop counter and tolerance\n",
    "    loop_count = 0\n",
    "    epsilon = 1\n",
    "    \n",
    "    # Loop until either tol or maxiter is satisfied or\n",
    "    while loop_count < maxiter:\n",
    "        # 2. Compute probability distribution\n",
    "        Pmp = MaxEnt_joint_dist(lambdas, products)\n",
    "        \n",
    "        # 3. Calculate moments associated with constraints\n",
    "        maxent_moments = np.array([MaxEnt_joint_moment(mRNA, protein, Pmp, x) \\\n",
    "                                   for x in exponents])\n",
    "        \n",
    "        # 4. Compute the âˆ†moments\n",
    "        delta_moments = constraints - maxent_moments\n",
    "        \n",
    "        # 5. calcualte the 2-norm error\n",
    "        epsilon = np.dot(delta_moments, delta_moments)\n",
    "        \n",
    "        # 6. If tolerance is satisfied break loop\n",
    "        if epsilon <= tol:\n",
    "            break\n",
    "        \n",
    "        if (verbose) and (loop_count % loop_print == 0):\n",
    "            print('loop count: ', loop_count)\n",
    "            print('2-norm error: ', round(epsilon, int(np.log10(tol))))\n",
    "        # a. Calculate Jacobian Matrix\n",
    "        # Initialize matrix\n",
    "        Jacobian = np.zeros([len(constraints), len(constraints)])\n",
    "        # Loop through exponents computing each entry of the matrix\n",
    "        for i, expi in enumerate(exponents):\n",
    "            for j, expj in enumerate(exponents):\n",
    "                Jacobian[i, j] = - MaxEnt_joint_moment(mRNA, protein, Pmp, \n",
    "                                   np.array(expi) + np.array(expj))\n",
    "        \n",
    "        # b. Calcualte step size for Lagrange multipliers\n",
    "        delta_lambdas = np.dot(np.linalg.inv(Jacobian), delta_moments)\n",
    "        # c. update lambdas\n",
    "        lambdas += delta_lambdas\n",
    "        \n",
    "        # update counter\n",
    "        loop_count += 1\n",
    "    print('# loops: ',loop_count)\n",
    "    \n",
    "    return lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-state unregulated promoter\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise to test the performance of this approximation let's fit the Maximum entropy model to the two-state unregulated promoter model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define the three functions needed to implement the first two moment constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the parameters for the *lacUV5* unregulated promoter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 promoter\n",
    "par_UV5 = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1)\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5['gp'] = gp\n",
    "\n",
    "# define rp based on the mean protein copy number per mRNA\n",
    "par_UV5['rp'] = 1000 * par_UV5['gp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `maxnetropy` package to fit the maximum entropy model.\n",
    "Let's do it systematically incrementing the number of moments used for the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the parameters in order to feed them to the moment functions\n",
    "m_param = ['kp_on', 'kp_off', 'rm', 'gm']\n",
    "p_param = ['kp_on', 'kp_off', 'rm', 'gm', 'rp', 'gp']\n",
    "par_m = [par_UV5.get(x) for x in m_param]\n",
    "par_p = [par_UV5.get(x) for x in p_param]\n",
    "\n",
    "# Write down the constraints\n",
    "# mRNA\n",
    "mRNA_moments = [chann_cap.first_unreg_m(*par_m),\\\n",
    "             chann_cap.second_unreg_m(*par_m),\\\n",
    "             chann_cap.third_unreg_m(*par_m)]\n",
    "# Protein\n",
    "protein_moments = [chann_cap.first_unreg_p(*par_p),\\\n",
    "                chann_cap.second_unreg_p(*par_p),\\\n",
    "                chann_cap.third_unreg_p(*par_p)]\n",
    "# Cross-correlations\n",
    "correlations = [chann_cap.mp_unreg_p(*par_p),\\\n",
    "                chann_cap.m2p_unreg_p(*par_p),\\\n",
    "                chann_cap.mp2_unreg_p(*par_p)]\n",
    "\n",
    "constraints = np.array(mRNA_moments + protein_moments + correlations)\n",
    "\n",
    "# Define exponents\n",
    "exponents = ([1, 0], [2, 0], [3, 0],\n",
    "             [0, 1], [0, 2], [0, 3],\n",
    "             [1, 1], [2, 1], [1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define a computationally more efficient sample space we will make use of what we know about the first and second moment. We will define the sample space as mean $\\pm $  $Y \\times$ standard deviation, where $Y$ is some factor.\n",
    "\n",
    "Let's define this sample space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract moments\n",
    "mRNA_mean = mRNA_moments[0]\n",
    "mRNA_std = np.sqrt(mRNA_moments[1] - mRNA_mean**2)\n",
    "protein_mean = protein_moments[0]\n",
    "protein_std = np.sqrt(protein_moments[1] - protein_mean**2)\n",
    "\n",
    "# Compute range\n",
    "std_factor = 3\n",
    "mRNA_range = [int(x) for x in [mRNA_mean - std_factor * mRNA_std,\n",
    "              mRNA_mean + std_factor * mRNA_std]]\n",
    "protein_range = [int(x) for x in [protein_mean - std_factor * protein_std,\n",
    "                 protein_mean + std_factor * protein_std]]\n",
    "\n",
    "# Define sample space\n",
    "mRNA_space = np.arange(*mRNA_range)\n",
    "protein_space = np.arange(*protein_range)\n",
    "\n",
    "# Eliminate negative numbers\n",
    "mRNA_space = mRNA_space[mRNA_space >= 0]\n",
    "protein_space = protein_space[protein_space >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# loops:  586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -7.33635314e-01,   4.45841878e-02,  -7.33132027e-04])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints = np.array(mRNA_moments)\n",
    "expo = exponents[0:3]\n",
    "lambda_mRNA = MaxEnt_newton_raphson(mRNA_space, protein_space, \n",
    "                                constraints, expo, tol=1E-5)\n",
    "lambda_mRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = np.zeros([len(constraints), len(mRNA_space), len(protein_space)])\n",
    "for i, exp in enumerate(expo):\n",
    "    products[i, :, :] = product_space(mRNA_space, protein_space, exp)\n",
    "\n",
    "Pmp = MaxEnt_joint_dist(lambda_mRNA, products).sum(axis=1)\n",
    "Pmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1155cd30>]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (http://matplotlib.org/) -->\n",
       "<svg height=\"251pt\" version=\"1.1\" viewBox=\"0 0 384 251\" width=\"384pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 251.36875 \n",
       "L 384.974688 251.36875 \n",
       "L 384.974688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 42.974688 224.64 \n",
       "L 377.774688 224.64 \n",
       "L 377.774688 7.2 \n",
       "L 42.974688 7.2 \n",
       "z\n",
       "\" style=\"fill:#e3dcd0;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 58.192869 224.64 \n",
       "L 58.192869 7.2 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\"/>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.640625 -1.8125 \n",
       "Q 20.265625 -1.8125 13.296875 8.609375 \n",
       "Q 6.34375 19.046875 6.34375 36.140625 \n",
       "Q 6.34375 53.21875 13.296875 63.640625 \n",
       "Q 20.265625 74.078125 31.640625 74.078125 \n",
       "Q 43.0625 74.078125 50 63.671875 \n",
       "Q 56.9375 53.265625 56.9375 36.140625 \n",
       "Q 56.9375 19.046875 50 8.609375 \n",
       "Q 43.0625 -1.8125 31.640625 -1.8125 \n",
       "z\n",
       "M 31.640625 5.421875 \n",
       "Q 46.734375 5.421875 46.734375 36.140625 \n",
       "Q 46.734375 66.84375 31.640625 66.84375 \n",
       "Q 16.609375 66.84375 16.609375 36.140625 \n",
       "Q 16.609375 5.421875 31.640625 5.421875 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-30\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(54.082635 241.662187)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 105.749688 224.64 \n",
       "L 105.749688 7.2 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\"/>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.15625 -0.296875 \n",
       "L 12.15625 8.296875 \n",
       "Q 19.34375 5.421875 25.828125 5.421875 \n",
       "Q 32.953125 5.421875 37.03125 9.609375 \n",
       "Q 41.109375 13.8125 41.109375 21.1875 \n",
       "Q 41.109375 29.109375 35.34375 33.28125 \n",
       "Q 29.59375 37.453125 18.703125 37.453125 \n",
       "Q 16.15625 37.453125 13.375 37.109375 \n",
       "L 13.375 72.265625 \n",
       "L 49.953125 72.265625 \n",
       "L 49.953125 63.875 \n",
       "L 21.828125 63.875 \n",
       "L 21.828125 44.828125 \n",
       "Q 35.75 44.828125 43.5625 38.421875 \n",
       "Q 51.375 32.03125 51.375 20.703125 \n",
       "Q 51.375 10.15625 44.265625 4.171875 \n",
       "Q 37.15625 -1.8125 24.65625 -1.8125 \n",
       "Q 19.09375 -1.8125 12.15625 -0.296875 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-35\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(101.639453 241.662187)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 153.306506 224.64 \n",
       "L 153.306506 7.2 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\"/>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 10 -->\n",
       "      <defs>\n",
       "       <path d=\"M 26.171875 0 \n",
       "L 26.171875 65.046875 \n",
       "L 14.75 65.046875 \n",
       "L 14.75 71.09375 \n",
       "L 35.84375 72.90625 \n",
       "L 35.84375 0 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-31\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(145.086037 241.662187)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-31\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 200.863324 224.64 \n",
       "L 200.863324 7.2 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\"/>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 15 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(192.642855 241.662187)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-31\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 248.420142 224.64 \n",
       "L 248.420142 7.2 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\"/>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.296875 0 \n",
       "L 8.296875 8.453125 \n",
       "Q 12.5 18.265625 25.296875 29.828125 \n",
       "L 30.8125 34.765625 \n",
       "Q 41.453125 44.390625 41.453125 53.859375 \n",
       "Q 41.453125 59.90625 37.8125 63.375 \n",
       "Q 34.1875 66.84375 27.78125 66.84375 \n",
       "Q 20.3125 66.84375 10.109375 61.03125 \n",
       "L 10.109375 69.53125 \n",
       "Q 19.734375 74.078125 29.25 74.078125 \n",
       "Q 39.40625 74.078125 45.53125 68.609375 \n",
       "Q 51.65625 63.140625 51.65625 54.109375 \n",
       "Q 51.65625 47.609375 48.546875 42.578125 \n",
       "Q 45.453125 37.546875 37.015625 30.375 \n",
       "L 33.296875 27.203125 \n",
       "Q 21.734375 17.390625 19.921875 8.453125 \n",
       "L 51.3125 8.453125 \n",
       "L 51.3125 0 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-32\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(240.199673 241.662187)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-32\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 295.97696 224.64 \n",
       "L 295.97696 7.2 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\"/>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 25 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(287.756491 241.662187)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-32\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 343.533778 224.64 \n",
       "L 343.533778 7.2 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\"/>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 30 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.15625 0.53125 \n",
       "L 10.15625 9.515625 \n",
       "Q 20.453125 5.421875 26.375 5.421875 \n",
       "Q 33.34375 5.421875 37.671875 9.421875 \n",
       "Q 42 13.421875 42 19.875 \n",
       "Q 42 35.109375 20.65625 35.109375 \n",
       "L 16.84375 35.109375 \n",
       "L 16.84375 41.609375 \n",
       "L 20.21875 41.65625 \n",
       "Q 40.234375 41.65625 40.234375 55.765625 \n",
       "Q 40.234375 66.84375 26.953125 66.84375 \n",
       "Q 19.828125 66.84375 11.140625 62.796875 \n",
       "L 11.140625 71.1875 \n",
       "Q 19.671875 74.078125 27.59375 74.078125 \n",
       "Q 38.375 74.078125 44.140625 69.78125 \n",
       "Q 49.90625 65.484375 49.90625 57.328125 \n",
       "Q 49.90625 44.578125 34.8125 39.15625 \n",
       "Q 52.296875 35.109375 52.296875 20.015625 \n",
       "Q 52.296875 9.8125 45.546875 4 \n",
       "Q 38.8125 -1.8125 27.046875 -1.8125 \n",
       "Q 20.359375 -1.8125 10.15625 0.53125 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-33\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(335.31331 241.662187)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-33\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 220.025244 \n",
       "L 377.774688 220.025244 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\"/>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.00 -->\n",
       "      <defs>\n",
       "       <path d=\"M 9.765625 0 \n",
       "L 9.765625 12.0625 \n",
       "L 21.828125 12.0625 \n",
       "L 21.828125 0 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-2e\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 225.036337)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 190.849967 \n",
       "L 377.774688 190.849967 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\"/>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.01 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 195.861061)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 161.674691 \n",
       "L 377.774688 161.674691 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\"/>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.02 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 166.685784)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 132.499414 \n",
       "L 377.774688 132.499414 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\"/>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.03 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 137.510508)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 103.324138 \n",
       "L 377.774688 103.324138 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\"/>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.04 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.640625 0 \n",
       "L 37.640625 20.453125 \n",
       "L 5.125 20.453125 \n",
       "L 5.125 27.734375 \n",
       "L 37.640625 72.265625 \n",
       "L 46.6875 72.265625 \n",
       "L 46.6875 28.328125 \n",
       "L 56.34375 28.328125 \n",
       "L 56.34375 20.453125 \n",
       "L 46.6875 20.453125 \n",
       "L 46.6875 0 \n",
       "z\n",
       "M 14.546875 28.328125 \n",
       "L 38.28125 28.328125 \n",
       "L 38.28125 60.453125 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-34\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 108.335232)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 74.148861 \n",
       "L 377.774688 74.148861 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_26\"/>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.05 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 79.159955)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 44.973585 \n",
       "L 377.774688 44.973585 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_28\"/>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.06 -->\n",
       "      <defs>\n",
       "       <path d=\"M 17.1875 37.453125 \n",
       "Q 24.078125 46.390625 34.515625 46.390625 \n",
       "Q 44 46.390625 50.03125 40.109375 \n",
       "Q 56.0625 33.84375 56.0625 24.03125 \n",
       "Q 56.0625 12.75 49.296875 5.46875 \n",
       "Q 42.53125 -1.8125 32.078125 -1.8125 \n",
       "Q 20.171875 -1.8125 13.421875 7.828125 \n",
       "Q 6.6875 17.484375 6.6875 34.515625 \n",
       "Q 6.6875 57.46875 18.453125 68.21875 \n",
       "Q 24.859375 74.125 36.140625 74.125 \n",
       "Q 42.671875 74.125 52.34375 71.390625 \n",
       "L 52.34375 62.984375 \n",
       "Q 42.140625 66.890625 35.546875 66.890625 \n",
       "Q 17.1875 66.890625 17.1875 37.453125 \n",
       "z\n",
       "M 46.390625 22.125 \n",
       "Q 46.390625 30.125 42.671875 34.78125 \n",
       "Q 38.96875 39.453125 32.515625 39.453125 \n",
       "Q 26.375 39.453125 21.96875 35.34375 \n",
       "Q 17.578125 31.25 17.578125 25.484375 \n",
       "Q 17.578125 16.40625 21.75 10.90625 \n",
       "Q 25.921875 5.421875 32.8125 5.421875 \n",
       "Q 39.0625 5.421875 42.71875 9.90625 \n",
       "Q 46.390625 14.40625 46.390625 22.125 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-36\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 49.984679)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 42.974688 15.798308 \n",
       "L 377.774688 15.798308 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_30\"/>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.07 -->\n",
       "      <defs>\n",
       "       <path d=\"M 15.046875 0 \n",
       "Q 16.453125 8.453125 19.0625 14.59375 \n",
       "Q 21.6875 20.75 28.328125 31.5 \n",
       "L 48.046875 63.234375 \n",
       "L 10.84375 63.234375 \n",
       "L 10.84375 72.265625 \n",
       "L 57.234375 72.265625 \n",
       "L 57.234375 63.234375 \n",
       "Q 29.4375 22.265625 26.125 0 \n",
       "z\n",
       "\" id=\"LucidaSansUnicode-37\"/>\n",
       "      </defs>\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 20.809402)scale(0.13 -0.13)\">\n",
       "       <use xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"63.232422\" xlink:href=\"#LucidaSansUnicode-2e\"/>\n",
       "       <use x=\"94.873047\" xlink:href=\"#LucidaSansUnicode-30\"/>\n",
       "       <use x=\"158.105469\" xlink:href=\"#LucidaSansUnicode-37\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_31\">\n",
       "    <path clip-path=\"url(#pfd2d4dc022)\" d=\"M 58.192869 214.756364 \n",
       "L 67.704233 209.522862 \n",
       "L 77.215597 200.792451 \n",
       "L 86.72696 187.524576 \n",
       "L 96.238324 169.121701 \n",
       "L 105.749688 145.805425 \n",
       "L 115.261051 118.839743 \n",
       "L 124.772415 90.470424 \n",
       "L 134.283778 63.553425 \n",
       "L 143.795142 40.974421 \n",
       "L 153.306506 25.047734 \n",
       "L 162.817869 17.083636 \n",
       "L 172.329233 17.235297 \n",
       "L 181.840597 24.626905 \n",
       "L 191.35196 37.675648 \n",
       "L 200.863324 54.483088 \n",
       "L 210.374687 73.18583 \n",
       "L 219.886051 92.199808 \n",
       "L 229.397415 110.341341 \n",
       "L 238.908778 126.843709 \n",
       "L 248.420142 141.304617 \n",
       "L 257.931506 153.600588 \n",
       "L 267.442869 163.795961 \n",
       "L 276.954233 172.063097 \n",
       "L 286.465597 178.620712 \n",
       "L 295.97696 183.690615 \n",
       "L 305.488324 187.469508 \n",
       "L 314.999687 190.11096 \n",
       "L 324.511051 191.71234 \n",
       "L 334.022415 192.301284 \n",
       "L 343.533778 191.815344 \n",
       "L 353.045142 190.065808 \n",
       "L 362.556506 186.670172 \n",
       "\" style=\"fill:none;stroke:#0072b2;stroke-linecap:round;stroke-width:2;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 42.974688 224.64 \n",
       "L 42.974688 7.2 \n",
       "\" style=\"fill:none;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 377.774688 224.64 \n",
       "L 377.774688 7.2 \n",
       "\" style=\"fill:none;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 42.974688 224.64 \n",
       "L 377.774688 224.64 \n",
       "\" style=\"fill:none;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 42.974688 7.2 \n",
       "L 377.774688 7.2 \n",
       "\" style=\"fill:none;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pfd2d4dc022\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"42.974688\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1084fe8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mRNA_space, Pmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop count:  0\n",
      "2-norm error:  10000.0\n",
      "loop count:  50\n",
      "2-norm error:  0.0\n",
      "loop count:  100\n",
      "2-norm error:  0.0\n",
      "# loops:  106\n"
     ]
    }
   ],
   "source": [
    "lambdas = MaxEnt_newton_raphson(mRNA_space, protein_space, \n",
    "                                constraints, exponents, verbose=True,\n",
    "                               loop_print=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# Plot something in the range to keep the axis of this plot\n",
    "ax.plot([mRNA_space.min(), mRNA_space.max()],\n",
    "        [protein_space.min(), protein_space.max()])\n",
    "\n",
    "# Reduce the margins so that it is only the plotting area we desire\n",
    "ax.margins(0)\n",
    "\n",
    "# Label axis\n",
    "ax.set_xlabel('mRNA / cell')\n",
    "ax.set_ylabel('protein / cell')\n",
    "\n",
    "# Generate a new axis to add the heatmap\n",
    "ax2 = fig.add_axes([0.12, 0.12, 0.8, 0.8], anchor='NE', zorder=0)\n",
    "\n",
    "# Plot heatmap in new axis\n",
    "cax = ax2.matshow(Pmp, aspect='auto', cmap='viridis', origin='lower')\n",
    "# turn off secondary plot axis\n",
    "ax2.axis('off')\n",
    "\n",
    "# Generate a colorbar with the concentrations\n",
    "cbar_ax = fig.add_axes([0.95, 0.25, 0.03, 0.5])\n",
    "\n",
    "# Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "cbar = fig.colorbar(cax, cax=cbar_ax, format='%.0E')\n",
    "\n",
    "# Label colorbar\n",
    "cbar.set_label('probability')\n",
    "# plt.savefig(figdir + 'MaxEnt_joint_PMF_unreg.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dist = True\n",
    "if fit_dist:\n",
    "    # Define the minimum entropy \n",
    "    model = MinDivergenceModel(features, samplespace, vectorized=False,\n",
    "                               verbose=False)\n",
    "    model.algorithm = 'Powell'\n",
    "    model.tol = 1E-3\n",
    "    model.paramstol = 1E-3\n",
    "    model.maxiter = 500\n",
    "    model.callingback = True\n",
    "    # Change the dimensionality of the array\n",
    "    X = np.reshape(constraints, (1, -1))\n",
    "    # Fit the model\n",
    "    model.fit(X)\n",
    "    # Change dill setting to allow the export of the functions\n",
    "    dill.settings['recurse'] = True\n",
    "\n",
    "    # Open file to save functions\n",
    "    with open(tmpdir + 'two_state_Pmp_maxEnt_II.dill', 'wb') as file:\n",
    "        dill.dump(model, file)\n",
    "        dill.dump(mRNA_space, file)\n",
    "        dill.dump(protein_space, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and sample space\n",
    "with open(tmpdir + 'two_state_Pmp_maxEnt_II.dill', 'rb') as file:\n",
    "    model = dill.load(file)\n",
    "    mRNA_space = dill.load(file)\n",
    "    protein_space = dill.load(file)\n",
    "\n",
    "# Convert probability to 2D matrix\n",
    "Pmp = model.probdist().reshape(len(mRNA_space), len(protein_space)).T\n",
    "Pmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# Plot something in the range to keep the axis of this plot\n",
    "ax.plot([mRNA_space.min(), mRNA_space.max()],\n",
    "        [protein_space.min(), protein_space.max()])\n",
    "\n",
    "# Reduce the margins so that it is only the plotting area we desire\n",
    "ax.margins(0)\n",
    "\n",
    "# Label axis\n",
    "ax.set_xlabel('mRNA / cell')\n",
    "ax.set_ylabel('protein / cell')\n",
    "\n",
    "# Generate a new axis to add the heatmap\n",
    "ax2 = fig.add_axes([0.12, 0.12, 0.8, 0.8], anchor='NE', zorder=0)\n",
    "\n",
    "# Plot heatmap in new axis\n",
    "cax = ax2.matshow(Pmp, aspect='auto', cmap='viridis', origin='lower')\n",
    "# turn off secondary plot axis\n",
    "ax2.axis('off')\n",
    "\n",
    "# Generate a colorbar with the concentrations\n",
    "cbar_ax = fig.add_axes([0.95, 0.25, 0.03, 0.5])\n",
    "\n",
    "# Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "cbar = fig.colorbar(cax, cax=cbar_ax, format='%.0E')\n",
    "\n",
    "# Label colorbar\n",
    "cbar.set_label('probability')\n",
    "# plt.savefig(figdir + 'MaxEnt_joint_PMF_unreg.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Three-state regulated promoter.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a function that computes the first two moments of the protein distribution as a function of the repressor copy number, repressor-DNA binding energy as well as the inducer concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_reg_p(moment, C, rep, eRA, \n",
    "                 k0=2.7E-3, kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 rp=0.0975, gp=97.53,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5):\n",
    "    '''\n",
    "    Computes the mean protein copy number  as a function  of all the \n",
    "    parameters that go into the chemical master equation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    moment : string.\n",
    "        Moment to be computed. Options: 'first', 'second' and 'third'.\n",
    "    C : array-like.\n",
    "        Concentration at which evaluate the probability.\n",
    "    rep: float.\n",
    "        repressor copy number per cell.\n",
    "    eRA : float.\n",
    "        Repressor binding energy [kBT]\n",
    "    rm : float.\n",
    "        transcription initiation rate. [time**-1]\n",
    "    gm : float.\n",
    "        mRNA degradation rate. [time**-1]\n",
    "    rp : float.\n",
    "        translation initiation rate. [time**-1]\n",
    "    gp : float.\n",
    "        protein degradation rate. [time**-1]\n",
    "    k0 : float.\n",
    "        diffusion limited rate of a repressor binding the promoter\n",
    "    kp_on : float.\n",
    "        RNAP on rate. [time**-1]\n",
    "    kp_off : float.\n",
    "        RNAP off rate. [time**-1]\n",
    "    Nns : float.\n",
    "        Number of non-specific binding sites\n",
    "    ki, ka : float.\n",
    "        dissociation constants for the inactive and active states respectively\n",
    "        in the MWC model of the lac repressor.\n",
    "    epsilon : float.\n",
    "        energetic barrier between the inactive and the active state.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    protein copy number moment\n",
    "    '''\n",
    "    # Convert C into np.array\n",
    "    C = np.array(C)\n",
    "    \n",
    "    # Calculate the repressor on rate including the MWC model\n",
    "    kr_on = k0 * rep * chann_cap.p_act(C, ka, ki, epsilon)\n",
    "    # Compute the repressor off-rate based on the on-rate and the binding energy\n",
    "    kr_off = chann_cap.kr_off_fun(eRA, k0, kp_on, kp_off, Nns)\n",
    "    \n",
    "    if moment == 'first':\n",
    "        return chann_cap.first_reg_p(kr_on, kr_off, kp_on, kp_off,\n",
    "                                     rm, gm, rp, gp)\n",
    "    elif moment == 'second':\n",
    "        return chann_cap.second_reg_p(kr_on, kr_off, kp_on, kp_off,\n",
    "                                      rm, gm, rp, gp)\n",
    "    elif moment == 'third':\n",
    "        return chann_cap.third_reg_p(kr_on, kr_off, kp_on, kp_off,\n",
    "                                     rm, gm, rp, gp)\n",
    "    else:\n",
    "        print('please specify first, second or third moment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that takes all these parameters, along with the necessary elements (sample space, constraints, functions to compute moments) and returns the maximum entropy distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxent_reg_p(constraint_dict, samplespace, C, rep, eRA,\n",
    "                 k0=2.7E-3, kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 rp=0.0975, gp=97.53,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5, algorithm='Powell',\n",
    "                 disp=False):\n",
    "    '''\n",
    "    Computes the MaxEnt distribution approximation as a function of all the \n",
    "    parameters that go into the chemical master equation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    constraint_dict : dictionary.\n",
    "        Dictionary containing the functions to compute the constraints.\n",
    "        The name of the entries should be the same as the name of the moments,\n",
    "        for example constraint_dict = {'first' : first}.\n",
    "    samplespace : array-like.\n",
    "        Bins to be evaluated in the maximum entropy approach.\n",
    "    C : array-like.\n",
    "        Concentrations at which evaluate the probability.\n",
    "    rep: float.\n",
    "        repressor copy number per cell.\n",
    "    eRA : float.\n",
    "        Repressor binding energy [kBT]\n",
    "    k0 : float.\n",
    "        diffusion limited rate of a repressor binding the promoter\n",
    "    kp_on : float.\n",
    "        RNAP on rate. [time**-1]\n",
    "    kp_off : float.\n",
    "        RNAP off rate. [time**-1]\n",
    "    rm : float.\n",
    "        transcription initiation rate. [time**-1]\n",
    "    gm : float.\n",
    "        mRNA degradation rate. [time**-1] \n",
    "    rp : float.\n",
    "        translation initiation rate. [time**-1]\n",
    "    gp : float.\n",
    "        protein degradation rate. [time**-1]\n",
    "    Nns : float.\n",
    "        Number of non-specific binding sites\n",
    "    ki, ka : float.\n",
    "        dissociation constants for the inactive and active states respectively\n",
    "        in the MWC model of the lac repressor.\n",
    "    epsilon : float.\n",
    "        energetic barrier between the inactive and the active state.\n",
    "    algorithm : str.\n",
    "        Algorithm to be used for the parameter optimization. See\n",
    "        maxentropy.BaseModel help for a list of the available algorithms.\n",
    "    disp : bool.\n",
    "        Boolean indicating if the function should display the concentration\n",
    "        which is computing at the moment\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    max_ent_dist : array. shape = len(C) x len(samplespace)\n",
    "        Maximum Entropy probability distribution of protein for each \n",
    "        concentration in C\n",
    "    '''\n",
    "    # Initialize matrix to save distributions\n",
    "    max_ent_dist = np.zeros([len(C), len(samplespace)])\n",
    "    # Loop through concentrations\n",
    "    for j, c in enumerate(C):\n",
    "        if disp:\n",
    "            print(c)\n",
    "        # Initialize list to save constraints and moments\n",
    "        const_fn = []\n",
    "        const_name = []\n",
    "        # Extract each constraint function and element into lists\n",
    "        for key, val in constraint_dict.items():\n",
    "            const_name.append(key)\n",
    "            const_fn.append(val)\n",
    "\n",
    "        # Initialize array to save moment values\n",
    "        moments = np.zeros(len(const_name))\n",
    "        # Compute the value of the moments given the constraints\n",
    "        for i, moment in enumerate(const_name): \n",
    "            moments[i] = moment_reg_p(moment, c, rep, eRA, \n",
    "                                      k0, kp_on, kp_off, rm, gm, rp, gp,\n",
    "                                      Nns, ka, ki, epsilon)\n",
    "\n",
    "        # Define the minimum entropy moel\n",
    "        model = MinDivergenceModel(const_fn, samplespace, algorithm=algorithm)\n",
    "        # Change the dimensionality of the moment array\n",
    "        X = np.reshape(moments, (1, -1))\n",
    "        # Fit the model\n",
    "        model.fit(X)\n",
    "        max_ent_dist[j, :] = model.probdist()\n",
    "    \n",
    "    # Return probability distribution\n",
    "    return max_ent_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to test the function.\n",
    "\n",
    "First let's define a dictionary containing all of the necessar parameters for a regulated lacUV5 promoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 regulated promoter\n",
    "par_UV5_reg = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5)\n",
    "\n",
    "# Define the k0 parameters in units of the mRNA degradation time\n",
    "k0_norm = 2.7E-3 / 0.00284 \n",
    "par_UV5_reg['k0'] = k0_norm\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5_reg['gp'] = gp\n",
    "\n",
    "# define rp based on the mean protein copy number per mRNA\n",
    "par_UV5_reg['rp'] = 1000 * par_UV5_reg['gp']\n",
    "\n",
    "print(par_UV5_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-moment MaxEnt approximation.\n",
    "\n",
    "Now let's define the necessary variables to compute the MaxEnt distributions for different IPTG concentrations **using only the first two moments** for the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second}\n",
    "\n",
    "# Define concentrations to test\n",
    "IPTG = [0, 1, 10, 50, 100, 1000] #ÂµM\n",
    "\n",
    "# Copy parameters and add repressor copy number and binding energy\n",
    "par = par_UV5_reg.copy()\n",
    "par['eRA'] = -13.9 #kBT\n",
    "par['rep'] = 260 #repressors / cell\n",
    "\n",
    "# Define the sample space\n",
    "samplespace = np.arange(int(2.5E4))\n",
    "\n",
    "dist_maxent_reg = maxent_reg_p(constraint_dict, samplespace, IPTG, \n",
    "                               algorithm='BFGS',\n",
    "                               disp=True, **par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot both the PMF and CDF together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chann_cap.pmf_cdf_plot(samplespace, dist_maxent_reg, \n",
    "                       IPTG, color_palette='Blues',\n",
    "             mean_mark=True, marker_height=8E-4, ylim=[0, 1E-3],\n",
    "             color_bar=True, cbar_label='[IPTG] ÂµL',\n",
    "             binstep=100,\n",
    "             title='O2 - R260', xlabel='protein / cell')\n",
    "\n",
    "plt.savefig(figdir + 'maxEnt_dist_protein_O2_R260_two.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-moment MaxEnt approximation.\n",
    "\n",
    "Now let's compute this **using three moments** to generate the MaxEnt distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second, 'third':third}\n",
    "\n",
    "# Define the sample space\n",
    "samplespace = np.arange(int(2.5E4))\n",
    "\n",
    "dist_maxent_reg = maxent_reg_p(constraint_dict, samplespace, IPTG, \n",
    "                               algorithm='Powell',\n",
    "                               disp=True, **par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chann_cap.pmf_cdf_plot(samplespace, dist_maxent_reg, \n",
    "                       IPTG, color_palette='Blues',\n",
    "             mean_mark=True, marker_height=8E-4, ylim=[0, 1E-3],\n",
    "             color_bar=True, cbar_label='[IPTG] ÂµL',\n",
    "             binstep=25,\n",
    "             title='O2 - R260', xlabel='protein / cell')\n",
    "\n",
    "plt.savefig(figdir + 'maxEnt_dist_protein_O2_R260_three.pdf', \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a notorious difference only at the low end expression level. Otherwise for high inducer concentrations the distributions look exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the function is working! And now we can generate an input-output matrix $P(p \\mid C)$ from which to compute the channel capacity using the Blahut-Arimoto algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the channel capacity\n",
    "\n",
    "Having this input-output function let's use the Blahut-Arimoto algorithm function to compute the channel capacity.\n",
    "\n",
    "First let's test it with the input-output matrix we generated for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, pc, loop_count = chann_cap.channel_capacity(dist_maxent_reg)\n",
    "\n",
    "print('The channel-capacity is {:.2f} bits'.format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now systematically build the input-output function for different repressor copy numbers and operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing two- vs three-moments approximations.\n",
    "\n",
    "Let's compare the effect of using two- vs. three-moments for the MaxEnt distribution approximation. First we will compute the channel capacity using only the first two moments to infer the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 regulated promoter\n",
    "par_UV5_reg = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5)\n",
    "# Define the k0 parameters in units of the mRNA degradation time\n",
    "k0_norm = 2.7E-3 / 0.00284 \n",
    "par_UV5_reg['k0'] = k0_norm\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5_reg['gp'] = gp\n",
    "\n",
    "# define rp based on the mean protein copy number per mRNA\n",
    "par_UV5_reg['rp'] = 1000 * par_UV5_reg['gp']\n",
    "\n",
    "\n",
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second}\n",
    "\n",
    "# Define the sample space\n",
    "samplespace = np.arange(int(2.5E4))\n",
    "\n",
    "# Define experimental concentrations in ÂµM\n",
    "c = [0, 0.1, 1, 5, 7.5, 10, 25, 50, 75, 100, 250, 500, 1000] # ÂµM\n",
    "\n",
    "# Define repressor copy numebers\n",
    "repressors = np.logspace(0, np.log10(2000), 50)\n",
    "repressors = np.unique(repressors.round(0))\n",
    "\n",
    "# Define operators and energies\n",
    "operators = ['O1', 'O2', 'O3', 'Oid']\n",
    "energies = [-15.3, -13.9, -9.7, -17]\n",
    "op_dict = dict(zip(operators, energies))\n",
    "op_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the parameters let's compute the channel capacity for each operator and repressor copy number using a parallelized function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_channcap = False\n",
    "if compute_channcap:\n",
    "    # initialize data frame to save channel capacity computation\n",
    "    df_channcap = pd.DataFrame(columns=['operator', 'repressor', 'channcap'])\n",
    "    # loop through operators\n",
    "    for op in operators:\n",
    "        print(op)\n",
    "        # Define function to compute in parallel the channel capacity\n",
    "        def cc_parallel(r):\n",
    "            par = par_UV5_reg.copy()\n",
    "            par['eRA'] = op_dict[op] #kBT\n",
    "            par['rep'] = r #repressors / cell\n",
    "            # Build transition matrix\n",
    "            QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                               algorithm='Powell', **par)\n",
    "            # Compute the channel capacity with the Blahut-Arimoto algorithm\n",
    "            cc = chann_cap.channel_capacity(QpC, epsilon=1E-3)[0]\n",
    "            return cc\n",
    "            # generate a series with the relevant data\n",
    "        # Run the function in parallel\n",
    "        ccaps = Parallel(n_jobs=6)(delayed(cc_parallel)(r) for r in repressors)\n",
    "        # Convert to tidy data frame\n",
    "        ccaps = pd.DataFrame(ccaps, columns=['channcap'])\n",
    "        ccaps.loc[:, 'operator'] = pd.Series([op] * len(ccaps))\n",
    "        ccaps.loc[:, 'repressor'] = pd.Series(repressors)\n",
    "\n",
    "        df_channcap = pd.concat([df_channcap, ccaps], axis=0)\n",
    "    df_channcap.to_csv(datadir + 'chann_cap_maxEnt_protein_two_moments.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Incomplete\n",
    "*I need to find a solution for the numerical instability of the `scipy.optimize` function that the `maxentropy` package depends on*\n",
    "\n",
    "---\n",
    "Now let's do the same using three moments to compute the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample space\n",
    "samplespace = np.arange(int(3E4))\n",
    "\n",
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second, 'third':third}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_channcap = False\n",
    "if compute_channcap:\n",
    "    # initialize data frame to save channel capacity computation\n",
    "    df_channcap = pd.DataFrame(columns=['operator', 'repressor', 'channcap'])\n",
    "    # loop through operators\n",
    "    for op in operators:\n",
    "        print(op)\n",
    "        # Define function to compute in parallel the channel capacity\n",
    "        def cc_parallel(r):\n",
    "            par = par_UV5_reg.copy()\n",
    "            par['eRA'] = op_dict[op] #kBT\n",
    "            par['rep'] = r #repressors / cell\n",
    "            # Build transition matrix\n",
    "            QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                               algorithm='Powell', **par)\n",
    "            # Compute the channel capacity with the Blahut-Arimoto algorithm\n",
    "            cc = chann_cap.channel_capacity(QpC, epsilon=1E-3)[0]\n",
    "            return cc\n",
    "            # generate a series with the relevant data\n",
    "        # Run the function in parallel\n",
    "        ccaps = Parallel(n_jobs=6)(delayed(cc_parallel)(r) for r in repressors)\n",
    "        # Convert to tidy data frame\n",
    "        ccaps = pd.DataFrame(ccaps, columns=['channcap'])\n",
    "        ccaps.loc[:, 'operator'] = pd.Series([op] * len(ccaps))\n",
    "        ccaps.loc[:, 'repressor'] = pd.Series(repressors)\n",
    "\n",
    "        df_channcap = pd.concat([df_channcap, ccaps], axis=0)\n",
    "    df_channcap.to_csv(datadir + 'chann_cap_maxEnt_protein_three_moments.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the repressor vs. channel capacity plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channcap_two = pd.read_csv(datadir + \\\n",
    "                              'chann_cap_maxEnt_protein_two_moments.csv',\n",
    "                              header=0, index_col=None)\n",
    "df_channcap_three = pd.read_csv(datadir + \\\n",
    "                              'chann_cap_maxEnt_protein_three_moments.csv',\n",
    "                              header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by operator\n",
    "df_group = df_channcap_two.groupby('operator')\n",
    "\n",
    "# Define colors for each operator\n",
    "colors = sns.color_palette('colorblind', n_colors=len(df_group))\n",
    "operators = [op for op, data in df_group]\n",
    "color_dict = dict(zip(operators, colors))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "# Loop through operators in the two-moment approximation\n",
    "for group, data in df_group:\n",
    "    # Plot data\n",
    "    ax.plot(data.repressor, data.channcap, label=group, \n",
    "            color=color_dict[group])\n",
    "    \n",
    "# Group by operator\n",
    "df_group = df_channcap_three.groupby('operator')\n",
    "# Loop through operators in the three-moment approximation\n",
    "for group, data in df_group:\n",
    "    # Plot data\n",
    "    ax.plot(data.repressor, data.channcap, label='', linestyle='--',\n",
    "            color=color_dict[group])\n",
    "\n",
    "ax.set_xlabel('repressor copy number')\n",
    "ax.set_ylabel('channel capacity (bits)')\n",
    "ax.set_xscale('log')\n",
    "first_legend = ax.legend(loc='upper center', title='operator', ncol=4)\n",
    "\n",
    "# Add secondary label to distinguish two- vs three-moment approximation\n",
    "# Add the legend manually to the current Axes.\n",
    "ax2 = ax.add_artist(first_legend)\n",
    "\n",
    "# \"plot\" a solid and a dashed line for the legend\n",
    "line1, = plt.plot([], [], color='black', label='two')\n",
    "line2, = ax.plot([], [], color='black', linestyle='--', label='three')\n",
    "# Create another legend.\n",
    "plt.legend(handles=[line1, line2], loc='lower center', frameon=False,\n",
    "           title='# moments')\n",
    "\n",
    "# Save figure.\n",
    "plt.savefig(figdir + 'repressor_vs_channcap_protein.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a numerical instability native to `scipy.optimize` that I can't get around when using all three moments. So for now I'll leave this behind and focus on the predictions made witht the two-moment approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_channcap_two.groupby('operator')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for group, data in df_group:\n",
    "    ax.plot(data.repressor, data.channcap, label=group)\n",
    "\n",
    "ax.set_xlabel('repressor copy number')\n",
    "ax.set_ylabel('channel capacity (bits)')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(loc=0, title='operator')\n",
    "plt.savefig(figdir + 'repressor_vs_channcap_protein.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing predictions with experimental data.\n",
    "\n",
    "Let's import the experimental data we have collected so far and compare it with the theory we have.\n",
    "\n",
    "For the experimental data since we do not have a correspondence between arbitrary fluorescent units and molecule count we used different bins for the data and computed the channel capacity at each of this bins. Empirically we see that around\n",
    "$10^2$ bins it gives the right result, so we will be using this bin number as our best estimate for the experimental data.\n",
    "\n",
    "First let's look at the files that contain the channel capacity experimental estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory where data is stored\n",
    "expdir = '../../data/csv_channcap_bootstrap/'\n",
    "\n",
    "# List files with the bootstrap sampling of the\n",
    "files = glob.glob(expdir + '*channcap_bootstrap.csv')\n",
    "files[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's systematically read each of the files, extract the data from the bin number closest to **100** and compute the channel capacity estimate for this bin number.\n",
    "\n",
    "But first let's define a couple of dictionaries to map from RBS name to repressor co py number and from operator yo binding energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionaries to map operator to binding energy and rbs to rep copy \n",
    "op_dict = dict(zip(['O1', 'O2', 'O3', 'Oid'], [-15.3, -13.9, -9.7, -17]))\n",
    "rbs_dict = dict(zip(['HG104', 'RBS1147', 'RBS446', 'RBS1027', 'RBS1', 'RBS1L'],\n",
    "                    [22, 60, 124, 260, 1220, 1740]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the data in a tidy `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index of entries to save\n",
    "index = ['date', 'bins', 'operator', 'rbs', \n",
    "         'binding energy', 'repressors', 'channcap']\n",
    "# Initialize DataFrame to save information\n",
    "df_cc_exp = pd.DataFrame(columns=index)\n",
    "\n",
    "# Define bin number to extract\n",
    "bin_target = 300\n",
    "\n",
    "# Loop through files\n",
    "for f in files:\n",
    "    # Split file name to extract info\n",
    "    str_split = f.replace(expdir, '').split('_')\n",
    "    # Extract date, operator and rbs info\n",
    "    date, op, rbs = str_split[0:3]\n",
    "    # Map the binding energy and repressor copy number\n",
    "    eRA, rep = op_dict[op], rbs_dict[rbs]\n",
    "    \n",
    "    # Read file\n",
    "    df_cc_bs = pd.read_csv(f, header=0)\n",
    "\n",
    "    # Select df_cc_bs closest to desired number of bins\n",
    "    # Find the index of the min df_cc_bs\n",
    "    bin_idx = (np.abs(df_cc_bs['bins'] - bin_target)).idxmin()\n",
    "    # Choose the bind number\n",
    "    bin_num = df_cc_bs.iloc[bin_idx]['bins']\n",
    "\n",
    "    # Keep only df_cc_bs with this bin number\n",
    "    df_cc_bs = df_cc_bs[df_cc_bs['bins'] == bin_num]\n",
    "\n",
    "    # Extrapolate to N -> oo\n",
    "    x = 1 / df_cc_bs.samp_size\n",
    "    y = df_cc_bs.channcap_bs\n",
    "    # Perform linear regression\n",
    "    lin_reg = np.polyfit(x, y, deg=1)\n",
    "    # Extract intercept to find channel capacity estimate\n",
    "    cc = lin_reg[1]\n",
    "\n",
    "    # Compile info into a pandas series to append it to the DataFrame\n",
    "    series = pd.Series([date, bin_num, op, rbs, eRA, rep, cc],\n",
    "                       index=index)\n",
    "    # Append to DataFrame\n",
    "    df_cc_exp = df_cc_exp.append(series, ignore_index=True)\n",
    "\n",
    "df_cc_exp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having extracted the data let's plot it on top of the predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by operator\n",
    "df_group = df_channcap_two.groupby('operator')\n",
    "\n",
    "# Define colors for each operator\n",
    "operators = df_channcap_two['operator'].unique()\n",
    "colors = sns.color_palette('colorblind', n_colors=len(operators))\n",
    "op_col_dict = dict(zip(operators, colors))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for group, data in df_group:\n",
    "    ax.plot(data.repressor, data.channcap, label=group, color=op_col_dict[group])\n",
    "    # Plot data from operator\n",
    "    ax.plot(df_cc_exp[df_cc_exp['operator'] == group]['repressors'], \n",
    "            df_cc_exp[df_cc_exp['operator'] == group]['channcap'], \n",
    "            lw=0, marker='o', color=op_col_dict[group], label='')\n",
    "\n",
    "# Label plot\n",
    "ax.set_xlabel('repressor copy number')\n",
    "ax.set_ylabel('channel capacity (bits)')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(loc=0, title='operator')\n",
    "plt.savefig(figdir + 'theory_vs_data_channcap_protein.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring systematic overestimate of the channel capacity.\n",
    "\n",
    "An interesting general trend when comparing the experimental vs theoretical channel capacity is that it seems as if the predictions systematically overestimate the the channel capacity.\n",
    "\n",
    "The reasons I can think of for this happening (in order of how likely each of them is) are:\n",
    "1. Since we are measuring with the microscope, the instrument itself increases the noise in the measurements. As a consequence we always end up measuring a lower channel capacity than the one we would obtain by directly counting the number of proteins per cell.\n",
    "2. Things such as the variability in number of repressors (copy number and active number of repressors) and RNAP copy number would reduce the predicted channel capacity.\n",
    "3. The parameters ($k_0$ and/or $r_p$) since are not directly known or inferred from our own self-consistent data are affecting the predictions.\n",
    "4. The non-linearity of the camera chip is affecting the measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third of these causes is easy to address. For a particular operator, binding energy and repressor copy number let's systematically change the parameters and see how they affect the predicted channel capacity prediction.\n",
    "\n",
    "Let's start by defining the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 regulated promoter\n",
    "par_UV5_reg = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5)\n",
    "# Define the k0 parameters in units of the mRNA degradation time\n",
    "k0_norm = 2.7E-3 / 0.00284 \n",
    "par_UV5_reg['k0'] = k0_norm\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5_reg['gp'] = gp\n",
    "\n",
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second}\n",
    "\n",
    "# Define experimental concentrations in ÂµM\n",
    "c = np.array([0, 0.1, 1, 5, 7.5, 10, 25, 50, 75, 100, 250, 500, 1000]) # ÂµM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters to be used\n",
    "par = par_UV5_reg.copy()\n",
    "par['eRA'] = -13.9 #kBT\n",
    "par['rep'] = 260 #repressors / cell\n",
    "par['rp'] = 1000 * par['gp']\n",
    "\n",
    "# Define concentrations to test\n",
    "c = [0, 1, 10, 50, 100, 1000] #ÂµM\n",
    "\n",
    "# Find a proxy for the mean protein copy number\n",
    "mean_p = moment_reg_p('first', 5000, **par)\n",
    "# Define sample depending on the current value of rp\n",
    "samplespace = np.arange(0, int(2 * mean_p))\n",
    "\n",
    "# Build transition matrix\n",
    "QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                   algorithm='Powell', disp=True, **par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the range of parameter variability for $r_p$ and let's compute the channel capacity for each of these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array of rp values to explore\n",
    "rp_array = np.logspace(1, 4, 18)\n",
    "\n",
    "compute_channcap = False\n",
    "if compute_channcap:\n",
    "    # Define function to compute in parallel the channel capacity\n",
    "    def cc_parallel(rp):\n",
    "        # Set parameters to be used\n",
    "        par = par_UV5_reg.copy()\n",
    "        par['eRA'] = -13.9 #kBT\n",
    "        par['rep'] = 260 #repressors / cell\n",
    "        par['rp'] = rp * par['gp']\n",
    "\n",
    "        # Find a proxy for the mean protein copy number\n",
    "        mean_p = moment_reg_p('first', 5000, **par)\n",
    "        # Define sample depending on the current value of rp\n",
    "        samplespace = np.arange(0, int(2 * mean_p))\n",
    "\n",
    "        # Build transition matrix\n",
    "        QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                           algorithm='Powell', **par)\n",
    "        # Compute the channel capacity with the Blahut-Arimoto algorithm\n",
    "        cc = chann_cap.channel_capacity(QpC, epsilon=1E-3)[0]\n",
    "        return cc\n",
    "        # generate a series with the relevant data\n",
    "    # Run the function in parallel\n",
    "    ccaps_rp = Parallel(n_jobs=6)(delayed(cc_parallel)(rp) for rp in rp_array)\n",
    "    df_rp = pd.DataFrame(np.vstack([rp_array, ccaps_rp]).T, \n",
    "                     columns=['rp_gp', 'channcap'])\n",
    "    df_rp.to_csv('../../data/csv_maxEnt_dist/channcap_rp.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the channel capacity as a function of this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rp = pd.read_csv(datadir + 'channcap_rp.csv', header=0, index_col=None)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(df_rp['rp_gp'], df_rp['channcap'])\n",
    "\n",
    "# Label plot\n",
    "plt.xlabel(r'$\\left\\langle \\right.$protein$\\left. \\right\\rangle$ / mRNA ' + \\\n",
    "           '($r_p / \\gamma_p$)')\n",
    "plt.ylabel('channel capacity (bits)')\n",
    "plt.xscale('log')\n",
    "plt.savefig(figdir + 'rp_vs_channcap_protein.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is definitely not the determining variable. We can see that from the $10^2$ to the $10^4$ range the result is effectively the same. And even when going down to $10^1$ the difference is less than 0.1 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
