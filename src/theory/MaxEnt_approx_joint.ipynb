{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy Approximation - Joint distribution P(m, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2018 Manuel Razo. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import dill\n",
    "import itertools\n",
    "\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import library to perform maximum entropy fits\n",
    "from maxentropy.skmaxent import FeatureTransformer, MinDivergenceModel\n",
    "# Import libraries to parallelize processes\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Import matplotlib stuff for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Seaborn, useful for graphics\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the utils for this project\n",
    "import chann_cap_utils as chann_cap\n",
    "\n",
    "# Set PBoC plotting style\n",
    "chann_cap.set_plotting_style()\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline (only use with static plots (non-Bokeh))\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "tmpdir = '../../tmp/'\n",
    "figdir = '../../fig/MaxEnt_approx_joint/'\n",
    "datadir = '../../data/csv_maxEnt_dist/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\LaTeX$ macros\n",
    "\n",
    "$\\newcommand{kpon}{k^p_{\\text{on}}}$\n",
    "$\\newcommand{kpoff}{k^p_{\\text{off}}}$\n",
    "$\\newcommand{kron}{k^r_{\\text{on}}}$\n",
    "$\\newcommand{kroff}{k^r_{\\text{off}}}$\n",
    "$\\newcommand{rm}{r _m}$\n",
    "$\\newcommand{rp}{r _p}$\n",
    "$\\newcommand{gm}{\\gamma _m}$\n",
    "$\\newcommand{gp}{\\gamma _p}$\n",
    "$\\newcommand{mm}{\\left\\langle m \\right\\rangle}$\n",
    "$\\newcommand{foldchange}{\\text{fold-change}}$\n",
    "$\\newcommand{avg}[1]{\\left\\langle #1 \\right\\rangle}$\n",
    "$\\newcommand{ee}[1]{\\left\\langle #1 \\right\\rangle}$\n",
    "$\\newcommand{bb}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{ll}[1]{\\underset{\\sim}{#1}}$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The joint distribution $P(m, p)$ using MaxEnt.\n",
    "\n",
    "So far we used the MaxEnt approach to approximate the marginal distributions for mRNA $P(m)$ and protein $P(p)$. In reality since the protein copy number depends on the mRNA count we have a joint distribution $P(m, p)$. By definition the marginals we have computed are of the form\n",
    "$$\n",
    "P(m) \\equiv \\sum_p P(m, p),\n",
    "\\tag{1}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "P(p) \\equiv \\sum_m P(m, p),\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "This joint distribution could contain relevant information that we lose when performing these marginalizations. Therefore in this notebook we will use the exact same MaxEnt approach as before to compute the joint distribution.\n",
    "\n",
    "For the case of the joing distribution we have moments for the mRNA marginal distribution\n",
    "$$\n",
    "\\ee{m^i} \\equiv \\sum_m \\sum_p m^i P(m, p),\n",
    "\\tag{3}\n",
    "$$\n",
    "and equivalent moments for the protein distribution\n",
    "$$\n",
    "\\ee{p^i} \\equiv \\sum_m \\sum_p p^i P(m, p).\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "We also know the steady-state value of cross-correlations of the form\n",
    "$$\n",
    "\\ee{m^i p^j} \\equiv \\sum_m \\sum_p m^i p^j P(m, p), \n",
    "\\tag{5}\n",
    "$$\n",
    "where $i, j \\in \\{1, 2\\}$.\n",
    "\n",
    "Using these moments we can follow the exact same strategy to compute the MaxEnt approximation of the joint distribution.\n",
    "\n",
    "That means that our MaxEnt approximate joint distribution $P_H(m, p)$ is of the form\n",
    "$$\n",
    "P_H(m, p) = {1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "\\sum_{i=1}^3\\lambda_i^{(m)} m^i +\n",
    "\\sum_{j=1}^3\\lambda_j^{(p)} p^j +\n",
    "\\sum_{i,j \\in \\{1, 2\\}}\\lambda_{ij}^{(mp)} m^i p^j\n",
    "\\right],\n",
    "\\tag{6}\n",
    "$$\n",
    "where all the $\\lambda$ terms represent the Lagrange multipliers that need to be numerically determined.\n",
    "\n",
    "Given this form of the distribution the MaxEnt moments $\\ee{m^ip^j}_H$ are given by\n",
    "$$\n",
    "\\ee{m^ip^j}_H \\equiv \\sum_m \\sum_p m^ip^j P_H(m, p).\n",
    "\\tag{7}\n",
    "$$\n",
    "\n",
    "Let's now look into how to obtain the value of the Lagrange multipliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Newton-Raphson algorithm\n",
    "\n",
    "Following [Smadbeck & Kaznessis, 2013](http://www.pnas.org/content/110/35/14261) we will use a Newton-Raphson algorithm to get at the value of these Lagrange multipliers.\n",
    "\n",
    "Let $\\ll{\\lambda}$ be an array containing all Lagrange multipliers, and $\\ll{\\mu_H}$ be the estimate of all the MaxEnt moments computed using $P_H(m, p)$. The steps listed by the authors go as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize Lagrange multipliers $\\ll{\\lambda} = \\ll{\\lambda_0}$ (Typically a guess of all zeros works).\n",
    "2. Calculate the joint distribution $P_H(m, p)$ as determined by Eq. 6.\n",
    "3. Calculate the moments used for the constraints $\\ll{\\mu_H}$ with Eq. 7.\n",
    "4. Calculate the difference between the **known** moments and the MaxEnt estimates as\n",
    "$$\n",
    "\\Delta\\ll{\\mu} = \\ll{\\mu} - \\ll{\\mu_H}.\n",
    "\\tag{8}\n",
    "$$\n",
    "5. Calculate the 2-norm error with\n",
    "$$\n",
    "\\varepsilon = \\ll{\\mu_H}^T \\ll{\\mu_H}\n",
    "\\tag{9}\n",
    "$$\n",
    "6. If $\\varepsilon \\leq$ `tol` (i.e. a user determined tolerance value) proceed to the last step 7. Otherwise\n",
    "\n",
    "    a. Calculate the Jacobian Matrix $\\bb{J}$ with entries\n",
    "    $$\n",
    "    J_{i,j} \\equiv {\\partial \\mu_{H,i} \\over \\partial \\lambda_j}.\n",
    "    \\tag{10}\n",
    "    $$\n",
    "    (We'll come back to how to compute this matrix)\n",
    "    b. The Newton-Raphson method uses a first-order Taylor expansion of the form\n",
    "    $$\n",
    "    \\Delta\\ll{\\mu} \\approx \\bb{J} \\Delta \\ll{\\lambda}.\n",
    "    \\tag{11}\n",
    "    $$\n",
    "    Therefore we can estimate the step size for each of our Lagrange multipliers\n",
    "    as\n",
    "    $$\n",
    "    \\Delta \\ll{\\lambda} \\approx \\bb{J}^{-1} \\Delta\\ll{\\mu}\n",
    "    \\tag{12}\n",
    "    $$\n",
    "    c. Using this approximation we update our estimates for the i$^{\\text{th}}$\n",
    "    iteration as\n",
    "    $$\n",
    "    \\ll{\\lambda}^{(i + 1)} = \\ll{\\lambda}^{(i)} + \\Delta \\ll{\\lambda}\n",
    "    \\tag{13}\n",
    "    $$\n",
    "    d. Repeat from step 2.\n",
    "7. Once the $\\varepsilon \\leq$ `tol` relationship is satisfied return the Lagrange multipliers values $\\ll{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian Matrix $\\bb{J}$\n",
    "\n",
    "To compute the derivative from Eq. 10 we need to be very careful with the indexing. First we will rewrite the MaxEnt distribution (Eq. 6) as\n",
    "$$\n",
    "P_H(m, p) = {1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "- \\sum_{i=1}^N \\lambda_i m^{x_i} p^{y_i},\n",
    "\\right],\n",
    "\\tag{14}\n",
    "$$\n",
    "where we index all Lagrange multipliers $\\lambda_i$ to be associated with each of the constraints of the form $\\ee{m^{x_i} p^{y_i}}$. In our specific case we have the Lagrange multipliers of the form:\n",
    "$$\n",
    "\\left\\{\n",
    "\\lambda_1 : \\ee{m},\n",
    "\\lambda_2 : \\ee{m^2},\n",
    "\\lambda_3 : \\ee{m^3},\\\\\n",
    "\\lambda_4 : \\ee{p},\n",
    "\\lambda_5 : \\ee{p^2},\n",
    "\\lambda_6 : \\ee{p^3},\\\\\n",
    "\\lambda_7 : \\ee{mp},\n",
    "\\lambda_8 : \\ee{m^2p},\n",
    "\\lambda_9 : \\ee{mp^2},\n",
    "\\right\\}\n",
    "\\tag{15}\n",
    "$$\n",
    "\n",
    "This implies that Eq. 10 is given by\n",
    "$$\n",
    "J_{i,j} = {\\partial \\over \\partial \\lambda_j} \\ee{m^{x_i} p^{y_j}}_H.\n",
    "\\tag{16}\n",
    "$$\n",
    "Combining Eq. 7 and Eq. 14 gives\n",
    "$$\n",
    "J_{i,j} = {\\partial \\over \\partial \\lambda_j}\\left(\n",
    "\\sum_m \\sum_p m^{x_i} p^{y_i}\n",
    "{1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "- \\sum_{k=1}^N \\lambda_k m^{x_k} p^{y_k},\n",
    "\\right]\n",
    "\\right).\n",
    "\\tag{17}\n",
    "$$\n",
    "Evaluating this derivative gives\n",
    "$$\n",
    "J_{i,j} = \\sum_m \\sum_p \\left( m^{x_i} p^{y_i} \\right)\n",
    "\\left( - m^{x_j} p^{y_j}  \\right)\n",
    "{1 \\over \\mathcal{Z}} \\exp \\left[\n",
    "- \\sum_{k=1}^N \\lambda_k m^{x_k} p^{y_k}\n",
    "\\right].\n",
    "\\tag{18}\n",
    "$$\n",
    "This is simplified to\n",
    "$$\n",
    "J_{i,j} =\\ee{m^{x_i + x_j} p ^{y_i + y_j}}_H\n",
    "\\tag{19}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the algorithm.\n",
    "\n",
    "In the following steps we will be implementing such algorithm\n",
    "\n",
    "The first thing we will define is a function to compute the \"product space\" $m^x p^y$ for a given selection of $m$ andp $p$ values. These products will be fed to the algorithm as a pre-computed entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_space(mRNA, protein, exponents=[0, 0]):\n",
    "    '''\n",
    "    Computes all the products of the form m**x * p**y for all possible pairs\n",
    "    of m and p given in the mRNA and protein arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mRNA, protein : array-like.\n",
    "        Selected range of mRNA and protein to be used as sample space for the\n",
    "        distribution\n",
    "    exponents : array-like. 2x1\n",
    "        Exponents for the product.\n",
    "        exponents[0] = mRNA exponent x\n",
    "        exponents[1] = mRNA exponent y\n",
    "    Returns\n",
    "    -------\n",
    "    prod_space : array-like. len(mRNA) x len(protein).\n",
    "        All possible pairwise products.\n",
    "        rows = mRNA\n",
    "        columns = protein\n",
    "    '''\n",
    "    # Build mRNA and protein grid\n",
    "    mm, pp = np.meshgrid(mRNA, protein)\n",
    "    \n",
    "    # Compute product and return all possible pairwise products\n",
    "    return (mm**exponents[0] * pp**exponents[1]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having this in hand let's define a function that takes an array of Lagrange multipliers `lambda_array` and a 3D array `products` of pre-computed products products and returns the **MaxEnt** probability distribution for each entry $(m, p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxEnt_joint_dist(lambda_array, products):\n",
    "    '''\n",
    "    Computs the MaxEnt probability distribution given constraints captured\n",
    "    by the Lagrange multipliers in the lambda_array list and all the products\n",
    "    associated with each of the Lagrange multipliers\n",
    "    Parameters\n",
    "    ----------\n",
    "    lambda_array : array-like. 1 x N.\n",
    "        List of Lagrange multipliers to be used to compute the MaxEnt\n",
    "        distribution.\n",
    "        N = Number of constraints\n",
    "    product : ndarray. mRNA x protein x N\n",
    "        3D array with matrices containing the products associated with each\n",
    "        of the Lagrange multipliers.\n",
    "    Returns\n",
    "    -------\n",
    "    MaxEnt_dist: array-like. len(mRNA) x len(protein)\n",
    "        Maximum entropy distribution for each pairwise m,p entry\n",
    "    '''\n",
    "    # Confirm that the number of constraints is the same as the number of \n",
    "    # associated products\n",
    "    if len(lambda_array) != products.shape[0]:\n",
    "        raise ValueError('The number of constraints must be the same as '+\\\n",
    "                         'the number of given products')\n",
    "    \n",
    "    # Compute the products and exponentiate\n",
    "    exp_lambdas_mp = np.exp(- np.sum(products * \\\n",
    "                           np.array(lambda_array)[:, np.newaxis, np.newaxis],\n",
    "                               axis=0))\n",
    "    # return the distribution\n",
    "    return exp_lambdas_mp / np.sum(exp_lambdas_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_samplespace = np.arange(50)\n",
    "protein_samplespace = np.arange(1000)\n",
    "\n",
    "# initialize matrix to save products\n",
    "products = np.zeros([3, len(mRNA_samplespace), len(protein_samplespace)])\n",
    "\n",
    "# Compute and save example moments\n",
    "exponents = [(1, 0), (0, 1), (1, 1)]\n",
    "\n",
    "# Loop through exponents and save products\n",
    "for i, expo in enumerate(exponents):\n",
    "    products[i, :, :] = product_space(mRNA_samplespace, protein_samplespace,\n",
    "                                     expo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      0,       0,       0, ...,       0,       0,       0],\n",
       "       [      0,       1,       4, ...,    2209,    2304,    2401],\n",
       "       [      0,       2,       8, ...,    4418,    4608,    4802],\n",
       "       ..., \n",
       "       [      0,     997,    3988, ..., 2202373, 2297088, 2393797],\n",
       "       [      0,     998,    3992, ..., 2204582, 2299392, 2396198],\n",
       "       [      0,     999,    3996, ..., 2206791, 2301696, 2398599]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRNA_samplespace = np.arange(0, 50)\n",
    "protein_samplespace = np.arange(0, 1000)\n",
    "prod = product_space(mRNA_samplespace, protein_samplespace, [2, 1])\n",
    "prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-state unregulated promoter\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise to test the performance of this approximation let's fit the Maximum entropy model to the two-state unregulated promoter model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define the three functions needed to implement the first two moment constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginalized moments\n",
    "# mRNA\n",
    "def m1(x):\n",
    "    return x[0]\n",
    "\n",
    "def m2(x):\n",
    "    return x[0]**2\n",
    "\n",
    "def m3(x):\n",
    "    return x[0]**3\n",
    "\n",
    "# protein\n",
    "def p1(x):\n",
    "    return x[1]\n",
    "\n",
    "def p2(x):\n",
    "    return x[1]**2\n",
    "\n",
    "def p3(x):\n",
    "    return x[1]**3\n",
    "\n",
    "# Cross correlations\n",
    "def mp_fn(x):\n",
    "    return x[0] * x[1]\n",
    "\n",
    "def m2p_fn(x):\n",
    "    return x[0]**2 * x[1]\n",
    "\n",
    "def mp2_fn(x):\n",
    "    return x[0] * x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the parameters for the *lacUV5* unregulated promoter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 promoter\n",
    "par_UV5 = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1)\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5['gp'] = gp\n",
    "\n",
    "# define rp based on the mean protein copy number per mRNA\n",
    "par_UV5['rp'] = 1000 * par_UV5['gp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `maxnetropy` package to fit the maximum entropy model.\n",
    "Let's do it systematically incrementing the number of moments used for the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the constraint functions into an array\n",
    "features = [m1, m2, m3, # mRNA\n",
    "            p1, p2, #p3, # protein\n",
    "            mp_fn, m2p_fn] #, mp2_fn] # cross correlations\n",
    "\n",
    "# Extract the parameters in order to feed them to the moment functions\n",
    "m_param = ['kp_on', 'kp_off', 'rm', 'gm']\n",
    "p_param = ['kp_on', 'kp_off', 'rm', 'gm', 'rp', 'gp']\n",
    "par_m = [par_UV5.get(x) for x in m_param]\n",
    "par_p = [par_UV5.get(x) for x in p_param]\n",
    "\n",
    "# Write down the constraints\n",
    "# mRNA\n",
    "mRNA_moments = [chann_cap.first_unreg_m(*par_m),\\\n",
    "             chann_cap.second_unreg_m(*par_m),\\\n",
    "             chann_cap.third_unreg_m(*par_m)]\n",
    "# Protein\n",
    "protein_moments = [chann_cap.first_unreg_p(*par_p),\\\n",
    "                chann_cap.second_unreg_p(*par_p)]\n",
    "# Cross-correlations\n",
    "correlations = [chann_cap.mp_unreg_p(*par_p),\\\n",
    "                chann_cap.m2p_unreg_p(*par_p)]#,\\\n",
    "#                 chann_cap.mp2_unreg_p(*par_p)]\n",
    "\n",
    "constraints = np.array(mRNA_moments + protein_moments + correlations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define a computationally more efficient sample space we will make use of what we know about the first and second moment. We will define the sample space as mean $\\pm $  $Y \\times$ standard deviation, where $Y$ is some factor.\n",
    "\n",
    "Let's define this sample space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract moments\n",
    "mRNA_mean = mRNA_moments[0]\n",
    "mRNA_std = np.sqrt(mRNA_moments[1] - mRNA_mean**2)\n",
    "protein_mean = protein_moments[0]\n",
    "protein_std = np.sqrt(protein_moments[1] - protein_mean**2)\n",
    "\n",
    "# Compute range\n",
    "std_factor = 3\n",
    "mRNA_range = [int(x) for x in [mRNA_mean - std_factor * mRNA_std,\n",
    "              mRNA_mean + std_factor * mRNA_std]]\n",
    "protein_range = [int(x) for x in [protein_mean - std_factor * protein_std,\n",
    "                 protein_mean + std_factor * protein_std]]\n",
    "\n",
    "# Define sample space\n",
    "mRNA_space = np.arange(*mRNA_range)\n",
    "protein_space = np.arange(*protein_range)\n",
    "\n",
    "# Eliminate negative numbers\n",
    "mRNA_space = mRNA_space[mRNA_space >= 0]\n",
    "protein_space = protein_space[protein_space >= 0]\n",
    "\n",
    "samplespace = list(itertools.product(mRNA_space, protein_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dist = True\n",
    "if fit_dist:\n",
    "    # Define the minimum entropy \n",
    "    model = MinDivergenceModel(features, samplespace, vectorized=False,\n",
    "                               verbose=False)\n",
    "    model.algorithm = 'Powell'\n",
    "    model.tol = 1E-3\n",
    "    model.paramstol = 1E-3\n",
    "    model.maxiter = 500\n",
    "    model.callingback = True\n",
    "    # Change the dimensionality of the array\n",
    "    X = np.reshape(constraints, (1, -1))\n",
    "    # Fit the model\n",
    "    model.fit(X)\n",
    "    # Change dill setting to allow the export of the functions\n",
    "    dill.settings['recurse'] = True\n",
    "\n",
    "    # Open file to save functions\n",
    "    with open(tmpdir + 'two_state_Pmp_maxEnt_II.dill', 'wb') as file:\n",
    "        dill.dump(model, file)\n",
    "        dill.dump(mRNA_space, file)\n",
    "        dill.dump(protein_space, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and sample space\n",
    "with open(tmpdir + 'two_state_Pmp_maxEnt_II.dill', 'rb') as file:\n",
    "    model = dill.load(file)\n",
    "    mRNA_space = dill.load(file)\n",
    "    protein_space = dill.load(file)\n",
    "\n",
    "# Convert probability to 2D matrix\n",
    "Pmp = model.probdist().reshape(len(mRNA_space), len(protein_space)).T\n",
    "Pmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# Plot something in the range to keep the axis of this plot\n",
    "ax.plot([mRNA_space.min(), mRNA_space.max()],\n",
    "        [protein_space.min(), protein_space.max()])\n",
    "\n",
    "# Reduce the margins so that it is only the plotting area we desire\n",
    "ax.margins(0)\n",
    "\n",
    "# Label axis\n",
    "ax.set_xlabel('mRNA / cell')\n",
    "ax.set_ylabel('protein / cell')\n",
    "\n",
    "# Generate a new axis to add the heatmap\n",
    "ax2 = fig.add_axes([0.12, 0.12, 0.8, 0.8], anchor='NE', zorder=0)\n",
    "\n",
    "# Plot heatmap in new axis\n",
    "cax = ax2.matshow(Pmp, aspect='auto', cmap='viridis', origin='lower')\n",
    "# turn off secondary plot axis\n",
    "ax2.axis('off')\n",
    "\n",
    "# Generate a colorbar with the concentrations\n",
    "cbar_ax = fig.add_axes([0.95, 0.25, 0.03, 0.5])\n",
    "\n",
    "# Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "cbar = fig.colorbar(cax, cax=cbar_ax, format='%.0E')\n",
    "\n",
    "# Label colorbar\n",
    "cbar.set_label('probability')\n",
    "# plt.savefig(figdir + 'MaxEnt_joint_PMF_unreg.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Three-state regulated promoter.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a function that computes the first two moments of the protein distribution as a function of the repressor copy number, repressor-DNA binding energy as well as the inducer concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_reg_p(moment, C, rep, eRA, \n",
    "                 k0=2.7E-3, kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 rp=0.0975, gp=97.53,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5):\n",
    "    '''\n",
    "    Computes the mean protein copy number  as a function  of all the \n",
    "    parameters that go into the chemical master equation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    moment : string.\n",
    "        Moment to be computed. Options: 'first', 'second' and 'third'.\n",
    "    C : array-like.\n",
    "        Concentration at which evaluate the probability.\n",
    "    rep: float.\n",
    "        repressor copy number per cell.\n",
    "    eRA : float.\n",
    "        Repressor binding energy [kBT]\n",
    "    rm : float.\n",
    "        transcription initiation rate. [time**-1]\n",
    "    gm : float.\n",
    "        mRNA degradation rate. [time**-1]\n",
    "    rp : float.\n",
    "        translation initiation rate. [time**-1]\n",
    "    gp : float.\n",
    "        protein degradation rate. [time**-1]\n",
    "    k0 : float.\n",
    "        diffusion limited rate of a repressor binding the promoter\n",
    "    kp_on : float.\n",
    "        RNAP on rate. [time**-1]\n",
    "    kp_off : float.\n",
    "        RNAP off rate. [time**-1]\n",
    "    Nns : float.\n",
    "        Number of non-specific binding sites\n",
    "    ki, ka : float.\n",
    "        dissociation constants for the inactive and active states respectively\n",
    "        in the MWC model of the lac repressor.\n",
    "    epsilon : float.\n",
    "        energetic barrier between the inactive and the active state.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    protein copy number moment\n",
    "    '''\n",
    "    # Convert C into np.array\n",
    "    C = np.array(C)\n",
    "    \n",
    "    # Calculate the repressor on rate including the MWC model\n",
    "    kr_on = k0 * rep * chann_cap.p_act(C, ka, ki, epsilon)\n",
    "    # Compute the repressor off-rate based on the on-rate and the binding energy\n",
    "    kr_off = chann_cap.kr_off_fun(eRA, k0, kp_on, kp_off, Nns)\n",
    "    \n",
    "    if moment == 'first':\n",
    "        return chann_cap.first_reg_p(kr_on, kr_off, kp_on, kp_off,\n",
    "                                     rm, gm, rp, gp)\n",
    "    elif moment == 'second':\n",
    "        return chann_cap.second_reg_p(kr_on, kr_off, kp_on, kp_off,\n",
    "                                      rm, gm, rp, gp)\n",
    "    elif moment == 'third':\n",
    "        return chann_cap.third_reg_p(kr_on, kr_off, kp_on, kp_off,\n",
    "                                     rm, gm, rp, gp)\n",
    "    else:\n",
    "        print('please specify first, second or third moment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that takes all these parameters, along with the necessary elements (sample space, constraints, functions to compute moments) and returns the maximum entropy distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxent_reg_p(constraint_dict, samplespace, C, rep, eRA,\n",
    "                 k0=2.7E-3, kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 rp=0.0975, gp=97.53,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5, algorithm='Powell',\n",
    "                 disp=False):\n",
    "    '''\n",
    "    Computes the MaxEnt distribution approximation as a function of all the \n",
    "    parameters that go into the chemical master equation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    constraint_dict : dictionary.\n",
    "        Dictionary containing the functions to compute the constraints.\n",
    "        The name of the entries should be the same as the name of the moments,\n",
    "        for example constraint_dict = {'first' : first}.\n",
    "    samplespace : array-like.\n",
    "        Bins to be evaluated in the maximum entropy approach.\n",
    "    C : array-like.\n",
    "        Concentrations at which evaluate the probability.\n",
    "    rep: float.\n",
    "        repressor copy number per cell.\n",
    "    eRA : float.\n",
    "        Repressor binding energy [kBT]\n",
    "    k0 : float.\n",
    "        diffusion limited rate of a repressor binding the promoter\n",
    "    kp_on : float.\n",
    "        RNAP on rate. [time**-1]\n",
    "    kp_off : float.\n",
    "        RNAP off rate. [time**-1]\n",
    "    rm : float.\n",
    "        transcription initiation rate. [time**-1]\n",
    "    gm : float.\n",
    "        mRNA degradation rate. [time**-1] \n",
    "    rp : float.\n",
    "        translation initiation rate. [time**-1]\n",
    "    gp : float.\n",
    "        protein degradation rate. [time**-1]\n",
    "    Nns : float.\n",
    "        Number of non-specific binding sites\n",
    "    ki, ka : float.\n",
    "        dissociation constants for the inactive and active states respectively\n",
    "        in the MWC model of the lac repressor.\n",
    "    epsilon : float.\n",
    "        energetic barrier between the inactive and the active state.\n",
    "    algorithm : str.\n",
    "        Algorithm to be used for the parameter optimization. See\n",
    "        maxentropy.BaseModel help for a list of the available algorithms.\n",
    "    disp : bool.\n",
    "        Boolean indicating if the function should display the concentration\n",
    "        which is computing at the moment\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    max_ent_dist : array. shape = len(C) x len(samplespace)\n",
    "        Maximum Entropy probability distribution of protein for each \n",
    "        concentration in C\n",
    "    '''\n",
    "    # Initialize matrix to save distributions\n",
    "    max_ent_dist = np.zeros([len(C), len(samplespace)])\n",
    "    # Loop through concentrations\n",
    "    for j, c in enumerate(C):\n",
    "        if disp:\n",
    "            print(c)\n",
    "        # Initialize list to save constraints and moments\n",
    "        const_fn = []\n",
    "        const_name = []\n",
    "        # Extract each constraint function and element into lists\n",
    "        for key, val in constraint_dict.items():\n",
    "            const_name.append(key)\n",
    "            const_fn.append(val)\n",
    "\n",
    "        # Initialize array to save moment values\n",
    "        moments = np.zeros(len(const_name))\n",
    "        # Compute the value of the moments given the constraints\n",
    "        for i, moment in enumerate(const_name): \n",
    "            moments[i] = moment_reg_p(moment, c, rep, eRA, \n",
    "                                      k0, kp_on, kp_off, rm, gm, rp, gp,\n",
    "                                      Nns, ka, ki, epsilon)\n",
    "\n",
    "        # Define the minimum entropy moel\n",
    "        model = MinDivergenceModel(const_fn, samplespace, algorithm=algorithm)\n",
    "        # Change the dimensionality of the moment array\n",
    "        X = np.reshape(moments, (1, -1))\n",
    "        # Fit the model\n",
    "        model.fit(X)\n",
    "        max_ent_dist[j, :] = model.probdist()\n",
    "    \n",
    "    # Return probability distribution\n",
    "    return max_ent_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to test the function.\n",
    "\n",
    "First let's define a dictionary containing all of the necessar parameters for a regulated lacUV5 promoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 regulated promoter\n",
    "par_UV5_reg = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5)\n",
    "\n",
    "# Define the k0 parameters in units of the mRNA degradation time\n",
    "k0_norm = 2.7E-3 / 0.00284 \n",
    "par_UV5_reg['k0'] = k0_norm\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5_reg['gp'] = gp\n",
    "\n",
    "# define rp based on the mean protein copy number per mRNA\n",
    "par_UV5_reg['rp'] = 1000 * par_UV5_reg['gp']\n",
    "\n",
    "print(par_UV5_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-moment MaxEnt approximation.\n",
    "\n",
    "Now let's define the necessary variables to compute the MaxEnt distributions for different IPTG concentrations **using only the first two moments** for the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second}\n",
    "\n",
    "# Define concentrations to test\n",
    "IPTG = [0, 1, 10, 50, 100, 1000] #µM\n",
    "\n",
    "# Copy parameters and add repressor copy number and binding energy\n",
    "par = par_UV5_reg.copy()\n",
    "par['eRA'] = -13.9 #kBT\n",
    "par['rep'] = 260 #repressors / cell\n",
    "\n",
    "# Define the sample space\n",
    "samplespace = np.arange(int(2.5E4))\n",
    "\n",
    "dist_maxent_reg = maxent_reg_p(constraint_dict, samplespace, IPTG, \n",
    "                               algorithm='BFGS',\n",
    "                               disp=True, **par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot both the PMF and CDF together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chann_cap.pmf_cdf_plot(samplespace, dist_maxent_reg, \n",
    "                       IPTG, color_palette='Blues',\n",
    "             mean_mark=True, marker_height=8E-4, ylim=[0, 1E-3],\n",
    "             color_bar=True, cbar_label='[IPTG] µL',\n",
    "             binstep=100,\n",
    "             title='O2 - R260', xlabel='protein / cell')\n",
    "\n",
    "plt.savefig(figdir + 'maxEnt_dist_protein_O2_R260_two.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-moment MaxEnt approximation.\n",
    "\n",
    "Now let's compute this **using three moments** to generate the MaxEnt distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second, 'third':third}\n",
    "\n",
    "# Define the sample space\n",
    "samplespace = np.arange(int(2.5E4))\n",
    "\n",
    "dist_maxent_reg = maxent_reg_p(constraint_dict, samplespace, IPTG, \n",
    "                               algorithm='Powell',\n",
    "                               disp=True, **par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chann_cap.pmf_cdf_plot(samplespace, dist_maxent_reg, \n",
    "                       IPTG, color_palette='Blues',\n",
    "             mean_mark=True, marker_height=8E-4, ylim=[0, 1E-3],\n",
    "             color_bar=True, cbar_label='[IPTG] µL',\n",
    "             binstep=25,\n",
    "             title='O2 - R260', xlabel='protein / cell')\n",
    "\n",
    "plt.savefig(figdir + 'maxEnt_dist_protein_O2_R260_three.pdf', \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a notorious difference only at the low end expression level. Otherwise for high inducer concentrations the distributions look exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the function is working! And now we can generate an input-output matrix $P(p \\mid C)$ from which to compute the channel capacity using the Blahut-Arimoto algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the channel capacity\n",
    "\n",
    "Having this input-output function let's use the Blahut-Arimoto algorithm function to compute the channel capacity.\n",
    "\n",
    "First let's test it with the input-output matrix we generated for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, pc, loop_count = chann_cap.channel_capacity(dist_maxent_reg)\n",
    "\n",
    "print('The channel-capacity is {:.2f} bits'.format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now systematically build the input-output function for different repressor copy numbers and operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing two- vs three-moments approximations.\n",
    "\n",
    "Let's compare the effect of using two- vs. three-moments for the MaxEnt distribution approximation. First we will compute the channel capacity using only the first two moments to infer the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 regulated promoter\n",
    "par_UV5_reg = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5)\n",
    "# Define the k0 parameters in units of the mRNA degradation time\n",
    "k0_norm = 2.7E-3 / 0.00284 \n",
    "par_UV5_reg['k0'] = k0_norm\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5_reg['gp'] = gp\n",
    "\n",
    "# define rp based on the mean protein copy number per mRNA\n",
    "par_UV5_reg['rp'] = 1000 * par_UV5_reg['gp']\n",
    "\n",
    "\n",
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second}\n",
    "\n",
    "# Define the sample space\n",
    "samplespace = np.arange(int(2.5E4))\n",
    "\n",
    "# Define experimental concentrations in µM\n",
    "c = [0, 0.1, 1, 5, 7.5, 10, 25, 50, 75, 100, 250, 500, 1000] # µM\n",
    "\n",
    "# Define repressor copy numebers\n",
    "repressors = np.logspace(0, np.log10(2000), 50)\n",
    "repressors = np.unique(repressors.round(0))\n",
    "\n",
    "# Define operators and energies\n",
    "operators = ['O1', 'O2', 'O3', 'Oid']\n",
    "energies = [-15.3, -13.9, -9.7, -17]\n",
    "op_dict = dict(zip(operators, energies))\n",
    "op_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the parameters let's compute the channel capacity for each operator and repressor copy number using a parallelized function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_channcap = False\n",
    "if compute_channcap:\n",
    "    # initialize data frame to save channel capacity computation\n",
    "    df_channcap = pd.DataFrame(columns=['operator', 'repressor', 'channcap'])\n",
    "    # loop through operators\n",
    "    for op in operators:\n",
    "        print(op)\n",
    "        # Define function to compute in parallel the channel capacity\n",
    "        def cc_parallel(r):\n",
    "            par = par_UV5_reg.copy()\n",
    "            par['eRA'] = op_dict[op] #kBT\n",
    "            par['rep'] = r #repressors / cell\n",
    "            # Build transition matrix\n",
    "            QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                               algorithm='Powell', **par)\n",
    "            # Compute the channel capacity with the Blahut-Arimoto algorithm\n",
    "            cc = chann_cap.channel_capacity(QpC, epsilon=1E-3)[0]\n",
    "            return cc\n",
    "            # generate a series with the relevant data\n",
    "        # Run the function in parallel\n",
    "        ccaps = Parallel(n_jobs=6)(delayed(cc_parallel)(r) for r in repressors)\n",
    "        # Convert to tidy data frame\n",
    "        ccaps = pd.DataFrame(ccaps, columns=['channcap'])\n",
    "        ccaps.loc[:, 'operator'] = pd.Series([op] * len(ccaps))\n",
    "        ccaps.loc[:, 'repressor'] = pd.Series(repressors)\n",
    "\n",
    "        df_channcap = pd.concat([df_channcap, ccaps], axis=0)\n",
    "    df_channcap.to_csv(datadir + 'chann_cap_maxEnt_protein_two_moments.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Incomplete\n",
    "*I need to find a solution for the numerical instability of the `scipy.optimize` function that the `maxentropy` package depends on*\n",
    "\n",
    "---\n",
    "Now let's do the same using three moments to compute the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample space\n",
    "samplespace = np.arange(int(3E4))\n",
    "\n",
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second, 'third':third}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_channcap = False\n",
    "if compute_channcap:\n",
    "    # initialize data frame to save channel capacity computation\n",
    "    df_channcap = pd.DataFrame(columns=['operator', 'repressor', 'channcap'])\n",
    "    # loop through operators\n",
    "    for op in operators:\n",
    "        print(op)\n",
    "        # Define function to compute in parallel the channel capacity\n",
    "        def cc_parallel(r):\n",
    "            par = par_UV5_reg.copy()\n",
    "            par['eRA'] = op_dict[op] #kBT\n",
    "            par['rep'] = r #repressors / cell\n",
    "            # Build transition matrix\n",
    "            QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                               algorithm='Powell', **par)\n",
    "            # Compute the channel capacity with the Blahut-Arimoto algorithm\n",
    "            cc = chann_cap.channel_capacity(QpC, epsilon=1E-3)[0]\n",
    "            return cc\n",
    "            # generate a series with the relevant data\n",
    "        # Run the function in parallel\n",
    "        ccaps = Parallel(n_jobs=6)(delayed(cc_parallel)(r) for r in repressors)\n",
    "        # Convert to tidy data frame\n",
    "        ccaps = pd.DataFrame(ccaps, columns=['channcap'])\n",
    "        ccaps.loc[:, 'operator'] = pd.Series([op] * len(ccaps))\n",
    "        ccaps.loc[:, 'repressor'] = pd.Series(repressors)\n",
    "\n",
    "        df_channcap = pd.concat([df_channcap, ccaps], axis=0)\n",
    "    df_channcap.to_csv(datadir + 'chann_cap_maxEnt_protein_three_moments.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the repressor vs. channel capacity plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channcap_two = pd.read_csv(datadir + \\\n",
    "                              'chann_cap_maxEnt_protein_two_moments.csv',\n",
    "                              header=0, index_col=None)\n",
    "df_channcap_three = pd.read_csv(datadir + \\\n",
    "                              'chann_cap_maxEnt_protein_three_moments.csv',\n",
    "                              header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by operator\n",
    "df_group = df_channcap_two.groupby('operator')\n",
    "\n",
    "# Define colors for each operator\n",
    "colors = sns.color_palette('colorblind', n_colors=len(df_group))\n",
    "operators = [op for op, data in df_group]\n",
    "color_dict = dict(zip(operators, colors))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "# Loop through operators in the two-moment approximation\n",
    "for group, data in df_group:\n",
    "    # Plot data\n",
    "    ax.plot(data.repressor, data.channcap, label=group, \n",
    "            color=color_dict[group])\n",
    "    \n",
    "# Group by operator\n",
    "df_group = df_channcap_three.groupby('operator')\n",
    "# Loop through operators in the three-moment approximation\n",
    "for group, data in df_group:\n",
    "    # Plot data\n",
    "    ax.plot(data.repressor, data.channcap, label='', linestyle='--',\n",
    "            color=color_dict[group])\n",
    "\n",
    "ax.set_xlabel('repressor copy number')\n",
    "ax.set_ylabel('channel capacity (bits)')\n",
    "ax.set_xscale('log')\n",
    "first_legend = ax.legend(loc='upper center', title='operator', ncol=4)\n",
    "\n",
    "# Add secondary label to distinguish two- vs three-moment approximation\n",
    "# Add the legend manually to the current Axes.\n",
    "ax2 = ax.add_artist(first_legend)\n",
    "\n",
    "# \"plot\" a solid and a dashed line for the legend\n",
    "line1, = plt.plot([], [], color='black', label='two')\n",
    "line2, = ax.plot([], [], color='black', linestyle='--', label='three')\n",
    "# Create another legend.\n",
    "plt.legend(handles=[line1, line2], loc='lower center', frameon=False,\n",
    "           title='# moments')\n",
    "\n",
    "# Save figure.\n",
    "plt.savefig(figdir + 'repressor_vs_channcap_protein.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a numerical instability native to `scipy.optimize` that I can't get around when using all three moments. So for now I'll leave this behind and focus on the predictions made witht the two-moment approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_channcap_two.groupby('operator')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for group, data in df_group:\n",
    "    ax.plot(data.repressor, data.channcap, label=group)\n",
    "\n",
    "ax.set_xlabel('repressor copy number')\n",
    "ax.set_ylabel('channel capacity (bits)')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(loc=0, title='operator')\n",
    "plt.savefig(figdir + 'repressor_vs_channcap_protein.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing predictions with experimental data.\n",
    "\n",
    "Let's import the experimental data we have collected so far and compare it with the theory we have.\n",
    "\n",
    "For the experimental data since we do not have a correspondence between arbitrary fluorescent units and molecule count we used different bins for the data and computed the channel capacity at each of this bins. Empirically we see that around\n",
    "$10^2$ bins it gives the right result, so we will be using this bin number as our best estimate for the experimental data.\n",
    "\n",
    "First let's look at the files that contain the channel capacity experimental estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory where data is stored\n",
    "expdir = '../../data/csv_channcap_bootstrap/'\n",
    "\n",
    "# List files with the bootstrap sampling of the\n",
    "files = glob.glob(expdir + '*channcap_bootstrap.csv')\n",
    "files[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's systematically read each of the files, extract the data from the bin number closest to **100** and compute the channel capacity estimate for this bin number.\n",
    "\n",
    "But first let's define a couple of dictionaries to map from RBS name to repressor co py number and from operator yo binding energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionaries to map operator to binding energy and rbs to rep copy \n",
    "op_dict = dict(zip(['O1', 'O2', 'O3', 'Oid'], [-15.3, -13.9, -9.7, -17]))\n",
    "rbs_dict = dict(zip(['HG104', 'RBS1147', 'RBS446', 'RBS1027', 'RBS1', 'RBS1L'],\n",
    "                    [22, 60, 124, 260, 1220, 1740]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the data in a tidy `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index of entries to save\n",
    "index = ['date', 'bins', 'operator', 'rbs', \n",
    "         'binding energy', 'repressors', 'channcap']\n",
    "# Initialize DataFrame to save information\n",
    "df_cc_exp = pd.DataFrame(columns=index)\n",
    "\n",
    "# Define bin number to extract\n",
    "bin_target = 300\n",
    "\n",
    "# Loop through files\n",
    "for f in files:\n",
    "    # Split file name to extract info\n",
    "    str_split = f.replace(expdir, '').split('_')\n",
    "    # Extract date, operator and rbs info\n",
    "    date, op, rbs = str_split[0:3]\n",
    "    # Map the binding energy and repressor copy number\n",
    "    eRA, rep = op_dict[op], rbs_dict[rbs]\n",
    "    \n",
    "    # Read file\n",
    "    df_cc_bs = pd.read_csv(f, header=0)\n",
    "\n",
    "    # Select df_cc_bs closest to desired number of bins\n",
    "    # Find the index of the min df_cc_bs\n",
    "    bin_idx = (np.abs(df_cc_bs['bins'] - bin_target)).idxmin()\n",
    "    # Choose the bind number\n",
    "    bin_num = df_cc_bs.iloc[bin_idx]['bins']\n",
    "\n",
    "    # Keep only df_cc_bs with this bin number\n",
    "    df_cc_bs = df_cc_bs[df_cc_bs['bins'] == bin_num]\n",
    "\n",
    "    # Extrapolate to N -> oo\n",
    "    x = 1 / df_cc_bs.samp_size\n",
    "    y = df_cc_bs.channcap_bs\n",
    "    # Perform linear regression\n",
    "    lin_reg = np.polyfit(x, y, deg=1)\n",
    "    # Extract intercept to find channel capacity estimate\n",
    "    cc = lin_reg[1]\n",
    "\n",
    "    # Compile info into a pandas series to append it to the DataFrame\n",
    "    series = pd.Series([date, bin_num, op, rbs, eRA, rep, cc],\n",
    "                       index=index)\n",
    "    # Append to DataFrame\n",
    "    df_cc_exp = df_cc_exp.append(series, ignore_index=True)\n",
    "\n",
    "df_cc_exp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having extracted the data let's plot it on top of the predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by operator\n",
    "df_group = df_channcap_two.groupby('operator')\n",
    "\n",
    "# Define colors for each operator\n",
    "operators = df_channcap_two['operator'].unique()\n",
    "colors = sns.color_palette('colorblind', n_colors=len(operators))\n",
    "op_col_dict = dict(zip(operators, colors))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for group, data in df_group:\n",
    "    ax.plot(data.repressor, data.channcap, label=group, color=op_col_dict[group])\n",
    "    # Plot data from operator\n",
    "    ax.plot(df_cc_exp[df_cc_exp['operator'] == group]['repressors'], \n",
    "            df_cc_exp[df_cc_exp['operator'] == group]['channcap'], \n",
    "            lw=0, marker='o', color=op_col_dict[group], label='')\n",
    "\n",
    "# Label plot\n",
    "ax.set_xlabel('repressor copy number')\n",
    "ax.set_ylabel('channel capacity (bits)')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(loc=0, title='operator')\n",
    "plt.savefig(figdir + 'theory_vs_data_channcap_protein.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring systematic overestimate of the channel capacity.\n",
    "\n",
    "An interesting general trend when comparing the experimental vs theoretical channel capacity is that it seems as if the predictions systematically overestimate the the channel capacity.\n",
    "\n",
    "The reasons I can think of for this happening (in order of how likely each of them is) are:\n",
    "1. Since we are measuring with the microscope, the instrument itself increases the noise in the measurements. As a consequence we always end up measuring a lower channel capacity than the one we would obtain by directly counting the number of proteins per cell.\n",
    "2. Things such as the variability in number of repressors (copy number and active number of repressors) and RNAP copy number would reduce the predicted channel capacity.\n",
    "3. The parameters ($k_0$ and/or $r_p$) since are not directly known or inferred from our own self-consistent data are affecting the predictions.\n",
    "4. The non-linearity of the camera chip is affecting the measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third of these causes is easy to address. For a particular operator, binding energy and repressor copy number let's systematically change the parameters and see how they affect the predicted channel capacity prediction.\n",
    "\n",
    "Let's start by defining the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the parameters fit for the lacUV5 regulated promoter\n",
    "par_UV5_reg = dict(kp_on=5.5, kp_off=28.9, rm=87.6, gm=1,\n",
    "                 Nns=4.6E6, ka=139, ki=0.53, epsilon=4.5)\n",
    "# Define the k0 parameters in units of the mRNA degradation time\n",
    "k0_norm = 2.7E-3 / 0.00284 \n",
    "par_UV5_reg['k0'] = k0_norm\n",
    "\n",
    "# define protein degradation rate in units of mRNA degradation rate\n",
    "gp = 0.000277 / 0.00284 \n",
    "par_UV5_reg['gp'] = gp\n",
    "\n",
    "# Define constraint dictionary containing the moments\n",
    "constraint_dict = {'first':first, 'second':second}\n",
    "\n",
    "# Define experimental concentrations in µM\n",
    "c = np.array([0, 0.1, 1, 5, 7.5, 10, 25, 50, 75, 100, 250, 500, 1000]) # µM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters to be used\n",
    "par = par_UV5_reg.copy()\n",
    "par['eRA'] = -13.9 #kBT\n",
    "par['rep'] = 260 #repressors / cell\n",
    "par['rp'] = 1000 * par['gp']\n",
    "\n",
    "# Define concentrations to test\n",
    "c = [0, 1, 10, 50, 100, 1000] #µM\n",
    "\n",
    "# Find a proxy for the mean protein copy number\n",
    "mean_p = moment_reg_p('first', 5000, **par)\n",
    "# Define sample depending on the current value of rp\n",
    "samplespace = np.arange(0, int(2 * mean_p))\n",
    "\n",
    "# Build transition matrix\n",
    "QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                   algorithm='Powell', disp=True, **par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the range of parameter variability for $r_p$ and let's compute the channel capacity for each of these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array of rp values to explore\n",
    "rp_array = np.logspace(1, 4, 18)\n",
    "\n",
    "compute_channcap = False\n",
    "if compute_channcap:\n",
    "    # Define function to compute in parallel the channel capacity\n",
    "    def cc_parallel(rp):\n",
    "        # Set parameters to be used\n",
    "        par = par_UV5_reg.copy()\n",
    "        par['eRA'] = -13.9 #kBT\n",
    "        par['rep'] = 260 #repressors / cell\n",
    "        par['rp'] = rp * par['gp']\n",
    "\n",
    "        # Find a proxy for the mean protein copy number\n",
    "        mean_p = moment_reg_p('first', 5000, **par)\n",
    "        # Define sample depending on the current value of rp\n",
    "        samplespace = np.arange(0, int(2 * mean_p))\n",
    "\n",
    "        # Build transition matrix\n",
    "        QpC = maxent_reg_p(constraint_dict, samplespace, c,\n",
    "                           algorithm='Powell', **par)\n",
    "        # Compute the channel capacity with the Blahut-Arimoto algorithm\n",
    "        cc = chann_cap.channel_capacity(QpC, epsilon=1E-3)[0]\n",
    "        return cc\n",
    "        # generate a series with the relevant data\n",
    "    # Run the function in parallel\n",
    "    ccaps_rp = Parallel(n_jobs=6)(delayed(cc_parallel)(rp) for rp in rp_array)\n",
    "    df_rp = pd.DataFrame(np.vstack([rp_array, ccaps_rp]).T, \n",
    "                     columns=['rp_gp', 'channcap'])\n",
    "    df_rp.to_csv('../../data/csv_maxEnt_dist/channcap_rp.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the channel capacity as a function of this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rp = pd.read_csv(datadir + 'channcap_rp.csv', header=0, index_col=None)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(df_rp['rp_gp'], df_rp['channcap'])\n",
    "\n",
    "# Label plot\n",
    "plt.xlabel(r'$\\left\\langle \\right.$protein$\\left. \\right\\rangle$ / mRNA ' + \\\n",
    "           '($r_p / \\gamma_p$)')\n",
    "plt.ylabel('channel capacity (bits)')\n",
    "plt.xscale('log')\n",
    "plt.savefig(figdir + 'rp_vs_channcap_protein.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is definitely not the determining variable. We can see that from the $10^2$ to the $10^4$ range the result is effectively the same. And even when going down to $10^1$ the difference is less than 0.1 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
