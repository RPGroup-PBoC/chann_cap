{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the input-output function $P(g\\mid R, c)$ for varying repressor copy number $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "from sympy import mpmath\n",
    "import scipy.optimize\n",
    "import scipy.special\n",
    "import scipy.integrate\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Import libraries to parallelize processes\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Import the utils for this project\n",
    "import chann_cap_utils as chann_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-computing analytical distributions of gene expession.\n",
    "\n",
    "Since the computation of the mRNA and protein steady-state probability distributions are computationally expensive, we can pre-compute the distribution for different repressor copy number and save the results as a lookup table to compute any desired quantity out of these distributions including the channel capacity and the variability in gene expression due to the stochasticity of the allosteric molecules.\n",
    "\n",
    "This notebook achieves the simple task of computing the mRNA and protein distribution for different repressor copy numbers saving the result into csv files that we can read with `numpy`.\n",
    "\n",
    "The matrices are arranged such that each row's index is given by the number of repressors and each column index indicates either the mRNA or protein count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-computing the mRNA distribution\n",
    "\n",
    "Let's start by saving the distribution for mRNA molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "k0 = 2.7E-3 # Used by Jones and Brewster\n",
    "\n",
    "# The MWC parameters come from the global fit to the O2 data\n",
    "mRNA_params = dict(ka=0.199, ki=0.00064, omega=np.exp(-4.5), \n",
    "                   k0=k0, gamma=0.00284, r_gamma=15.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the mRNA copy numbers to evaluate\n",
    "# It is break up in blocks to run the process in parallel\n",
    "mRNA_grid = np.reshape(np.arange(0, 50), [-1, 10])\n",
    "\n",
    "# define the array of repressor copy numbers to evaluate the function in\n",
    "R_array = np.arange(0, 1001)\n",
    "\n",
    "kon_array = [chann_cap.kon_fn(-17, mRNA_params['k0']),\n",
    "             chann_cap.kon_fn(-15.3, mRNA_params['k0']),\n",
    "             chann_cap.kon_fn(-13.9, mRNA_params['k0']),\n",
    "             chann_cap.kon_fn(-9.7, mRNA_params['k0'])]\n",
    "kon_operators = ['Oid', 'O1', 'O2', 'O3']\n",
    "\n",
    "compute_matrix = True\n",
    "if compute_matrix:\n",
    "    for j, kon in enumerate(kon_array):\n",
    "        print('operator : ' + kon_operators[j])\n",
    "        # Set the value for the kon\n",
    "        mRNA_params['kon'] = kon\n",
    "        # Initialize transition matrix\n",
    "        QmR = np.zeros([mRNA_grid.size, len(R_array)])\n",
    "        for i, r in enumerate(R_array):\n",
    "            if r%100==0:\n",
    "                print('repressors : {:d}'.format(r))\n",
    "            mRNA_params['rep'] = r * 1.66\n",
    "            # -- Parallel computation of distribution -- #\n",
    "            lnm_list = list()\n",
    "            # loop through the concentrations\n",
    "            # define a function to run in parallel the computation\n",
    "            def lnm_parallel(m):\n",
    "                lnm = chann_cap.log_p_m_mid_C(C=0, mRNA=m, **mRNA_params)\n",
    "                return lnm\n",
    "            lnm_list.append(Parallel(n_jobs=7)(delayed(lnm_parallel)(m) \\\n",
    "                                               for m in mRNA_grid))\n",
    "            # -- Building and cleaning the transition matrix -- #\n",
    "            for k, lnm in enumerate(lnm_list):\n",
    "                # Initialize the matrix of zeros where the normalized\n",
    "                # distribution will live\n",
    "                p_norm = np.zeros_like(lnm)\n",
    "                p = np.exp(lnm)\n",
    "                # Compute the cumulative sum of the protein copy number\n",
    "                p_sum = np.cumsum(np.sum(p, axis=1))\n",
    "                # Find the first block that is already normalized given \n",
    "                # the tolerance value\n",
    "                norm_idx = np.where((p_sum <= 1 + 1E-5) & \\\n",
    "                                    (p_sum >= 1 - 1E-5))[0][-1]\n",
    "                # add all the probability values of these blocks to our matrix\n",
    "                p_norm[0:norm_idx, :] = p[0:norm_idx, :]\n",
    "            QmR[:, i] = p_norm.ravel()\n",
    "            # Check that all distributions for each concentration are normalized\n",
    "        np.savetxt('../../tmp/QmR_' + kon_operators[j] +\\\n",
    "                   '_0_1000_literature_param.csv', QmR, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-computing the protien distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Protein parameters\n",
    "k0 = 2.7E-3 # From Jones & Brewster\n",
    "prot_params = dict(ka=141.52, ki=0.56061, epsilon=4.5,\n",
    "                   kon=chann_cap.kon_fn(-9.7, k0),\n",
    "                   k0=k0,\n",
    "                   gamma_m=0.00284, r_gamma_m=15.7,\n",
    "                   gamma_p=0.000277, r_gamma_p=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operator : O2\n",
      "repressors : 0\n"
     ]
    }
   ],
   "source": [
    "# Define the protein blocks to evaluate in parallel\n",
    "# Break into blocks to compute the distributions in parallel\n",
    "prot_grid = np.reshape(np.arange(0, 4000), [-1, 50])\n",
    "\n",
    "# define the array of repressor copy numbers to evaluate the function in\n",
    "R_array = np.arange(0, 1050)\n",
    "\n",
    "# Setting the kon parameter based on k0 and the binding energies form stat. mech.\n",
    "kon_array = [chann_cap.kon_fn(-13.9, prot_params['k0']),\n",
    "             chann_cap.kon_fn(-15.3, prot_params['k0']),\n",
    "             chann_cap.kon_fn(-9.7, prot_params['k0']),\n",
    "             chann_cap.kon_fn(-17, prot_params['k0'])]\n",
    "kon_operators = ['O2', 'O1', 'O3', 'Oid']\n",
    "kon_dict = dict(zip(kon_operators, kon_array))\n",
    "\n",
    "compute_matrix = True\n",
    "if compute_matrix:\n",
    "    for kon, op in enumerate(kon_operators):\n",
    "        print('operator : ' + op)\n",
    "        # Set the value for the kon\n",
    "        prot_params['kon'] = kon_dict[op]\n",
    "        # Define filename\n",
    "        file = '../../data/csv_protein_dist/lnp_' + op + '_DJ_RB.csv'\n",
    "    # If the file exists read the file, find the maximum number of repressors\n",
    "    # And compute from this starting point.\n",
    "        if os.path.isfile(file): \n",
    "            df = pd.read_csv(file, index_col=0)\n",
    "            max_rep = df.repressor.max()\n",
    "            df = df[df.repressor != max_rep]\n",
    "            df.to_csv(file)\n",
    "            r_array = np.arange(max_rep, np.max(R_array) + 1)\n",
    "        else:\n",
    "            r_array = R_array\n",
    "\n",
    "        # Loop through repressor copy numbers\n",
    "        for i, r in enumerate(r_array):\n",
    "            if r%50==0:\n",
    "                print('repressors : {:d}'.format(r))\n",
    "            prot_params['rep'] = r * 1.66\n",
    "            # -- Parallel computation of distribution -- #\n",
    "            # define a function to run in parallel the computation\n",
    "            def lnp_parallel(p):\n",
    "                lnp = chann_cap.log_p_p_mid_C(C=0, protein=p, **prot_params)\n",
    "                df = pd.DataFrame([r] * len(p), index=p, columns=['repressor'])\n",
    "                df.loc[:, 'protein'] = pd.Series(p, index=df.index)\n",
    "                df.loc[:, 'lnp'] = lnp\n",
    "                \n",
    "                # if file does not exist write header \n",
    "                if not os.path.isfile(file): \n",
    "                    df.to_csv(file) \n",
    "                else: # else it exists so append without writing the header\n",
    "                    df.to_csv(file, mode='a', header=False)\n",
    "            Parallel(n_jobs=40)(delayed(lnp_parallel)(p) for p in prot_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the lookup tables\n",
    "\n",
    "These calculations can sometimes be numerically unstable due to the complicated confluent hypergeometric function. What can happen is that by the time the probability is basically zero (i.e. the $\\ln P \\ll 0$) there can be some \"jumps\" where the calcualtion overshoots. But this happens for probability values that should be very close to zero, so it is very easy to discard these values.\n",
    "\n",
    "We will define a function to pre-process these lookup tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_lnp(df, group_col='repressor', lnp_col='lnp',\n",
    "                    output_col='prob', tol=-20):\n",
    "    '''\n",
    "    Pre-processes the lookup tables containing the log probability of a protein\n",
    "    copy number for different repressor copy numbers eliminating the values\n",
    "    that were numerically unstable, and returning the data frame with a column\n",
    "    containing the processed probability.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : df\n",
    "        Data frame containing the log probabilities.\n",
    "    group_col : str.\n",
    "        Name of the column in the data frame to be used to group the distributions\n",
    "    lnp_col : str.\n",
    "        Name of the column containing the log probability\n",
    "    output_col : str.\n",
    "        Name of the column that will contain the processed probability\n",
    "    tol : float.\n",
    "        log probability under which to consider values as probability zero.\n",
    "        This is important since some of the calculations goe to < -300\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas dataframe containing the processed probability.\n",
    "    '''\n",
    "    # Remove duplicated rows\n",
    "    df = df[[not x for x in df.duplicated()]]\n",
    "    \n",
    "    # Group by group_col\n",
    "    df_group = df.groupby(group_col)\n",
    "    \n",
    "    # Initialize data frame where to save the processed data\n",
    "    df_clean = pd.DataFrame(columns=df.columns)\n",
    "    # Loop through each group, computing the log probability making sure that\n",
    "    # There is no numerical overshoot and that the very small lnp are set to 0\n",
    "    # probability\n",
    "    for group, data in df_group:\n",
    "        data.sort(columns='protein', inplace=True)\n",
    "        # Set the new column to be all probability zero\n",
    "        data.loc[:, output_col] = [0.0] * len(data)\n",
    "        # Exponentiate the good log probabilities\n",
    "        data.loc[(data.lnp > tol) & (data.lnp < 0), output_col] =\\\n",
    "        pd.Series(np.exp(data.loc[(data.lnp > tol) & (data.lnp < 0), lnp_col]))\n",
    "        # Make sure cumulative sum still adds to zero\n",
    "        cumsum = np.cumsum(data[output_col])\n",
    "        data.loc[cumsum > 1, output_col] = 0\n",
    "        # Append to the clean data frame\n",
    "        df_clean = pd.concat([df_clean, data])\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the function let's pre-process the matrices we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/csv_protein_dist/lnp_O3_all_RBS1027_fit.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/razo/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:38: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/Users/razo/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:3304: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  na_position=na_position)\n",
      "/Users/razo/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/razo/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('../../data/csv_protein_dist/*O3_all*.csv')\n",
    "for f in files:\n",
    "    print(f)\n",
    "    df = pd.read_csv(f, header=0, index_col=0, comment='#')\n",
    "    df_clean = pre_process_lnp(df)\n",
    "    df_clean.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
