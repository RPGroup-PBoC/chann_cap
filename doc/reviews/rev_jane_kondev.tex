\section{Jane Kondev}

I very much enjoyed reading this. Here are some comments. I hope they're useful.

Sorry it took so long to get back to you.

\begin{tcolorbox}
I don't understand this:

``The implication of this biological noise is that cells do not have an infinite
resolution to distinguish signals and, as a consequence, there is a one-to-many
mapping between iputs and outputs.''

There is also a possibility that different inputs give the same output (because
not all environmental conditions are relevant to the cell?).
\end{tcolorbox}

We really appreciate this comment and the ones that follow. It is clear that
Jane took the time to thoroughly read the manuscript. As we try to make our
results as transparent and understandable as possible, this kind of
clarifications are immensely useful for us. The point we were trying to make
with this sentence is that for a given input there are multiple possible
outputs, but we completely agree that in such a statement it is not clear that
there can also be overlapping outputs for different inputs. To make things more
clear we changed the following in the text:

``The implication of this biological noise is that cells do not have an infinite
resolution to distinguish signals and, as a consequence, there is a one-to-many
mapping between inputs and outputs. \textbf{Furthermore, given the limited
number of possible outputs, there are overlapping responses between different
inputs}.''

If this is the point that was trying to be made, we hope that this extended
explanation suffices to inform the reader about the possible overlapping
responses for different inputs.

\begin{tcolorbox}
Is the use of mutual information in the context of cell sensing an important
assumption of the paper?
\end{tcolorbox}

We again greatly appreciate this input. This has been a matter of previous
discussion with  other people that have taken a look at the paper. The question
being: If the main effort in the paper is to build the probabilistic
input-output function $P(p \mid c)$, why focus so much on the goal of computing
the channel capacity?

We completely agree that the majority of the effort goes into constructing this
input-output function. But the reason we decided to include the information
theoretic scope on the paper is because we think that through this framework we
can put our results into a context. If one can agree that a gene regulatory
system that responds to an external signal is a molecular implementation of a
sensor and an actuator, then knowing the channel capacity of such sensor gives
an intuitive sense of its performance limits. Moreover an open question in the
field is how the logic that allows cells to sense their environment with high
precision is built out of noisy molecular components. Our study makes progress
towards understanding the interplay between biophysical parameters such as
protein copy number and protein-DNA binding affinity can have on the information
processing capacity of these gene regulatory systems.

Interesting findings came out of such an analysis. For example, the channel
capacity shown in Fig. 5(A) shows that there is an ``optimal'' repressor copy
number for a given binding site that maximizes the information transmission.
This interesting interplay between parameters was a new finding for experts in
the field such as Gasper Tkacik since for their theoretical models, in order to
get such an optimal point to exist, they needed to include a cost term for
sensing. This raises some interesting hypothesis such as if natural selection
were to act on a simple repression system to maximize the information processing
capacity, we would expect to find an optimal combination of binding site and
repressor copy number.

\begin{tcolorbox}
  From the text:

``These predictions are then contrasted with experimental data, where the
channel capacity is inferred from single-cell distributions...''

I'm missing something. Channel capacity is obtained by maximizing mutual
information over all $P(c)$. How do you experimentally scan through all $P(c)$?
\end{tcolorbox}

We again appreciate this excellent comment to clarify things for the reader. The
experimental measurements were done under 12 different concentrations of inducer
$c$ ranging from 0 $\mu$M to 5000 $\mu$M. These concentrations were previously
chosen in order to capture the three main parts of an induction curve: 1) The
leakiness, i.e. the expression even in the absence of inducer, 2) the
saturation, i.e. the maximum expression under saturating concentrations of
inducer, and 3) the transition, i.e. the region of the induction curve with
positive slope on a log-log plot where the system goes from minimum to maximum
expression \cite{Razo-Mejia2018}.

Given the degree of overlap between input-output distributions these 12 well
distributed concentrations suffice to capture all ``expression domains'' for our
system. In other words, the spacing between these concentrations captures all
representative expression distributions that can be uniquely resolved by the
system. To confirm that this is true we have done theoretical analysis where we
calculated the channel capacity using 50 evenly spaced inducer concentrations,
and we obtained the exact same result as wen using these 12 concentrations. This
is possible because the values that we are obtaining are $<2$ bits, meaning that
even 4 properly spaced concentrations would be able to capture all expression
domains for our system.

\begin{tcolorbox}
In Fig. 1 caption:
``As the phenotype (protein level) serves as the internal representation of the
environmental state (inducer concentration), the probability of a cell being in
a specific environment is a function of the probability of the response given
that environmental state''

Sounds like you are referring to $P(c)$ but in fact your mean $P(c \mid p)$.
\end{tcolorbox}

We appreciate this excellent feedback. We apologize for poor wording. We have
added the following line that includes the mathematical definitions to make
things more precise.

``As the phenotype (protein level) serves as the internal representation of the
environmental state (inducer concentration), the probability of a cell being in
a specific environment given this internal representation $P(c \mid p)$ is a
function of the probability of the response given that environmental state $P(p
\mid c)$.''

\begin{tcolorbox}
I've been curious to what extend the approximation of protein degradation being
a Poission process is a good one. When in fact "degradation" is really binomial
partitioning. I think Paulsson has a paper on noise due to partitioning...
\end{tcolorbox}

We thank again Jane for such a wonderful feedback. It commonly assumed that for
the particular bacterial systems we like to study under steady exponential
growth the protein degradation term is caused by binomial partitioning during
growth. In fact for our inferences we set $\gp$ the protein degradation rate to
be zero and we explicitly account for binomial partitioning. The reason we wrote
the full equation with the Poisson process describing protein degradation is
because if one wants to compare the results of assuming a single promoter copy
in the genome at steady state where no explicit account for binomial
partitioning is implemented, i.e. just setting these time derivatives to zero,
the protein degradation term is a necessary condition to reach such steady
state.

We added the following text after discussing the master equation:

``As we will discuss later in Section 1.4 the protein degradation term $\gp$ is
set to zero since we do not consider protein degradation as a Poission process,
but rather we explicitly implement binomial partitioning as the cells grow and
divide.''

\begin{tcolorbox}
With respect to the matrix equation:

Is it necessary/useful to rewrite the equations in this way?
\end{tcolorbox}

We thank again Jane's comments. All of them have proved so far to be extremely
helpful to make our approach and findings much more transparent for every
reader. We believe that this matrix notation becomes very handy and useful when
we set ourselves the task of computing any moment of the distribution $\ee{m^x
p^y}$. Writing the general moment dynamics equation using this notation gives a
clear interpretation of how each process (mRNA and protein production and
degradation) enter to the moment dynamics. Furthermore we would argue that this
notation would be preferable for the main text, leaving the individual
definitions of each of the promoter states dynamics to the SI.

\begin{tcolorbox}
In the text:

``We do not consider cells uniformly distributed along the cell cycle since it
is known that cells follow an exponential distribution, having more younger than
older cells at any time point''

I don't understand this. I guess you're talking about a distribution of division
times $t_d$?
\end{tcolorbox}

We appreciate the request for a clarification. This point does not refer to a
distribution of division times $t_d$ as a random variable. As a matter of fact
the exponential distribution discussed here is derived assuming all cells divide
exactly after $t_d - t_o$ time, i.e. the distribution of division times is a
delta function. The surprising fact of this calculation (which is included as
an Appendix at the end of the paper) is that given the nature of steady
exponential  growth there are always more younger than older cells. It is a
surprising result, but can be intuitively thought as follows. If the culture is
growing exponentially, that means that all the time there is an increasing
number of cells. That means for example that if in a time interval $\Delta t$
$N$ ``old'' cells divided, these produced $2N$ ``young'' cells. So at any point
there is always more younger than older cells.

\begin{tcolorbox}
Would it make sense to compare these distributions to exact obtained from a
stochastic simulation? Just to see how good is the MaxEnt.
\end{tcolorbox}

We thank Jane for the comment. It is a interesting and appealing point to
compare the results obtained from the Maximum entropy approach with
distributions obtained from a Gillespie simulation. The computational challenge
that these simulations present is the large possible number of states in the
simulation. What we mean by this is that our mRNA count goes from roughtly 0 to
about 50 mRNA, while the protein has a range of values from 0 to basically
$4 \times 10^4$. That makes this simulation have $\approx 10^6$ possible states.
What this means is that we would have to run many many simulations for a
considerably large time in order to get good samples out of this distribution.

That is not to belittle this suggestion or claim that it is not important. Maybe
a better suggestion would be to implement such a stochastic simulation once the
paper has been submitted to keep the ball rolling at this point.

\begin{tcolorbox}
  About Fig 5. Is the agreement necessarily true if the experimental and
  theoretical protein distributions agree?
\end{tcolorbox}

We thank Jane for this great comment. Just as we discussed before we see the
channel capacity as an intuitive metric of what are the performance limits of
these molecular sensing systems. Having said that it is true that as long as the
theoretical input-output distributions $P(p \mid c)$ agree with the experimental
ones these curves of mutual information should show such agreement. This is
because all what the Blahut-Arimoto algorithm is doing is finding an optimal
input distribution $P(c)$ given a \textbf{fixed} input-output function
$P(p \mid c)$.

\begin{tcolorbox}
From the discussion:

``Beautiful work along these lines has been done in the context of the
developmental program of the early \textit{Drosophila} embryo [3, 15]. These
studies demonstrated that the input-output function of the pair-rule genes works
at channel capacity, suggesting that selection has acted on these signaling
pathways, pushing them to operate at the limit of what the physics of these
systems allows.''

I am not sure if/how your Fig. 5 differs from this? Does it demonstrate optimal
information processing by \textit{E. coli} or not?
\end{tcolorbox}

We appreciate this question. The work by the group of Bialek and Gregor on the
early \textit{Drosophila} embryo has shown that the input-output function in
their system works at channel capacity. The way they reach this suggestive
conclusion is via a similar process to our inference:
\begin{enumerate}
  \item First they measure single-cell input and output levels along the embryo
  to reconstruct an approximate $P(\text{output} \mid \text{input})$.
  \item Then given this fixed input-output function, they implement either their
  analytical small noise approximation or the same numerical procedure as us
  based on the Blahut-Arimoto algorithm to find the optimal $P(\text{input})$
  that maximizes the mutual information $I(\text{input}; \text{output})$.
  \item Finally, since they do not get to choose what the input distribution
  $P(\text{input})$ is, but it is whatever the embryo experiences given the
  morphogen gradients in the cell, they can compared the result of the numerical
  computation of the optimal $P(\text{input})$ with the actual distribution that
  cells along the embryo experience. What they found is that the distribution
  obtained with the Blahut-Arimoto algorithm looks extremely similar to what
  actual cells within an embryo observe.
\end{enumerate}
Based on this comparison between the optimal input-output distribution and the
actual distribution that cells ``observe'' is that they conclude that the
construction of the input-output function allows the cells to gather as much
information about the input as possible.

Since for our case cells do not control the input distribution $P(c)$, we have
no standard to which compare our input distributions at channel capacity as
obtained by the Blahut-Arimoto algorithm $P^*(c)$. Some people have suggested
interesting approaches known as ``reverse ecology'' where the input
distributions obtained by computing the channel capacity are assumed to be a
reflection of the evolutionary history of environments that cells have
experienced \cite{Bowsher2012}. This construction nevertheless relies on the
strong assumption that all sensing systems work at channel capacity, i.e. they
have been optimize over evolutionary time to match the environmental state
distribution.
